{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a79c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# pipeline: prep -> run (subprocess) -> collect -> plot (jpg+pgf) -> latex\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, sys, re, json, time, subprocess, textwrap\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple, Set\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# Project paths\n",
    "# -----------------------\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "DATA_DIR     = PROJECT_ROOT / \"data\" / \"fuzzy\"\n",
    "RESULTS_DIR  = PROJECT_ROOT / \"results\" / \"fuzzy\"\n",
    "for p in (DATA_DIR, RESULTS_DIR): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "class DatasetPreparer:\n",
    "    \"\"\"\n",
    "    Handles all dataset preparation: downloading, replicating, and converting.\n",
    "    \"\"\"\n",
    "    def __init__(self, project_root: Path, data_dir: Path):\n",
    "        self.project_root = project_root\n",
    "        self.data_dir = data_dir\n",
    "        if str(self.project_root) not in sys.path:\n",
    "            sys.path.insert(0, str(self.project_root))\n",
    "\n",
    "    def _filename_from_url(self, url: str) -> str:\n",
    "        return Path(url.split(\"?\")[0]).name\n",
    "\n",
    "    def _download(self, url: str) -> Path:\n",
    "        filename = self._filename_from_url(url)\n",
    "        name_root = Path(filename).stem\n",
    "        dst_dir = self.data_dir / name_root\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out = dst_dir / filename\n",
    "        if out.exists():\n",
    "            print(f\"[download] Using cached: {out}\")\n",
    "            return out\n",
    "        legacy = self.data_dir / filename\n",
    "        if legacy.exists():\n",
    "            out.write_bytes(legacy.read_bytes())\n",
    "            print(f\"[download] Moved legacy file -> {out}\")\n",
    "            return out\n",
    "        print(f\"[download] Fetch {url}\")\n",
    "        r = requests.get(url, timeout=60); r.raise_for_status()\n",
    "        out.write_bytes(r.content)\n",
    "        print(f\"[download] Saved {out}\")\n",
    "        return out\n",
    "\n",
    "    def prepare(self, url: str, sf: int) -> Tuple[Dict[str, Path], int, str]:\n",
    "        \"\"\"\n",
    "        Runs the full dataset preparation pipeline.\n",
    "        Returns (paths_dict, quant_mult, dataset_name)\n",
    "        \"\"\"\n",
    "        original = self._download(url)\n",
    "        dataset_name = original.parent.name\n",
    "        sf = max(1, int(sf))\n",
    "\n",
    "        # 1) replicate floating text\n",
    "        from scripts.fuzzy.replicate_file import replicate_file\n",
    "        floating_text = original.with_name(f\"{original.stem}_SF{sf}{original.suffix}\")\n",
    "        if floating_text.exists():\n",
    "            print(f\"[prep] Using existing: {floating_text.name}\")\n",
    "        else:\n",
    "            replicate_file(str(original), sf, str(floating_text))\n",
    "            print(f\"[prep] Made: {floating_text.name}\")\n",
    "\n",
    "        # 2) make fixed text + quant_mult\n",
    "        from scripts.fuzzy.fixedpoint_normalize import process_file\n",
    "        fixed_text = process_file(str(floating_text))\n",
    "\n",
    "        # 3) convert both to parquet\n",
    "        from scripts.fuzzy.convert_to_parquet import convert_text_to_parquet\n",
    "        fixed_parquet = convert_text_to_parquet(fixed_text)\n",
    "        floating_parquet = convert_text_to_parquet(floating_text)\n",
    "\n",
    "        quant_mult = int(Path(fixed_parquet).stem.split(\"_fixed_\")[-1])\n",
    "        \n",
    "        paths = {\n",
    "            \"original\": original,\n",
    "            \"floating_text\": floating_text,\n",
    "            \"floating_parquet\": floating_parquet,\n",
    "            \"fixed_text\": fixed_text,\n",
    "            \"fixed_parquet\": fixed_parquet,\n",
    "        }\n",
    "        print(f\"[prep] Dataset '{dataset_name}' (SF={sf}) prepared.\")\n",
    "        return paths, quant_mult, dataset_name\n",
    "\n",
    "\n",
    "class ExperimentRunner:\n",
    "    \"\"\"\n",
    "    Runs all mining subprocesses for a given prepared dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, project_root: Path, ds_dir: Path, \n",
    "                 dataset_paths: Dict[str, Path], quant_mult: int):\n",
    "        self.project_root = project_root\n",
    "        self.ds_dir = ds_dir\n",
    "        self.logs_dir = self.ds_dir / \"logs\"\n",
    "        self.paths = dataset_paths\n",
    "        self.quant_mult = quant_mult\n",
    "        \n",
    "        self.logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def _run_subprocess(self, args: List[str], log_path: Path, err_path: Path, \n",
    "                        extra_env: Optional[Dict[str, str]] = None) -> int:\n",
    "        env = os.environ.copy()\n",
    "        env[\"PYTHONPATH\"] = str(self.project_root) + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "        if extra_env:\n",
    "            env.update({k: str(v) for k, v in extra_env.items()})\n",
    "            \n",
    "        print(\"[run] \", \" \".join(args))\n",
    "        with open(log_path, \"w\") as out, open(err_path, \"w\") as err:\n",
    "            proc = subprocess.run(args, cwd=self.project_root, env=env, \n",
    "                                  stdout=out, stderr=err, text=True)\n",
    "        print(f\"[run] exit={proc.returncode}  log={log_path}  err={err_path}\")\n",
    "        return proc.returncode\n",
    "\n",
    "    def run_cuffi(self, sup_int: int, params: Dict[str, Any]):\n",
    "        allocator = params.get(\"allocator\", \"rmm_managed\")\n",
    "        gds = params.get(\"gds\", \"off\")\n",
    "        \n",
    "        patterns_path = self.ds_dir / f\"patterns_cuffi_{allocator}_{gds}_sup{sup_int}.txt\"\n",
    "        log_path = self.logs_dir / f\"cuffi_sup{sup_int}.out\"\n",
    "        err_path = self.logs_dir / f\"cuffi_sup{sup_int}.err\"\n",
    "\n",
    "        cmd = [\n",
    "            sys.executable, \"-m\", \"src.algorithms.fuzzy.cuFFIMiner\",\n",
    "            str(self.paths[\"fixed_parquet\"]), str(int(sup_int)), str(int(self.quant_mult)),\n",
    "            \"-o\", str(patterns_path), \"--allocator\", allocator, \"--gds\", gds,\n",
    "        ]\n",
    "        self._run_subprocess(cmd, log_path, err_path)\n",
    "\n",
    "    def run_naive_floating(self, sup_int: int):\n",
    "        sup_float = sup_int / max(1, int(self.quant_mult))\n",
    "        patterns_path = self.ds_dir / f\"patterns_naive_floating_sup{sup_int}.txt\"\n",
    "        log_path = self.logs_dir / f\"naive_floating_sup{sup_int}.out\"\n",
    "        err_path = self.logs_dir / f\"naive_floating_sup{sup_int}.err\"\n",
    "\n",
    "        cmd = [\n",
    "            sys.executable, \"-m\", \"src.algorithms.fuzzy.naiveFFIMiner\",\n",
    "            str(self.paths[\"floating_parquet\"]), f\"{sup_float:.12g}\", \"-o\", str(patterns_path),\n",
    "        ]\n",
    "        self._run_subprocess(cmd, log_path, err_path)\n",
    "\n",
    "    def run_naive_fixed(self, sup_int: int):\n",
    "        sup_float = sup_int / max(1, int(self.quant_mult))\n",
    "        patterns_path = self.ds_dir / f\"patterns_naive_fixed_sup{sup_int}.txt\"\n",
    "        log_path = self.logs_dir / f\"naive_fixed_sup{sup_int}.out\"\n",
    "        err_path = self.logs_dir / f\"naive_fixed_sup{sup_int}.err\"\n",
    "        \n",
    "        cmd = [\n",
    "            sys.executable, \"-m\", \"src.algorithms.fuzzy.naiveFFIMiner\",\n",
    "            str(self.paths[\"fixed_parquet\"]), f\"{sup_float:.12g}\", \"-o\", str(patterns_path),\n",
    "        ]\n",
    "        self._run_subprocess(cmd, log_path, err_path)\n",
    "\n",
    "    def run_ffiminer(self, sup_int: int):\n",
    "        patterns_path = self.ds_dir / f\"patterns_ffiminer_sup{sup_int}.txt\"\n",
    "        log_path = self.logs_dir / f\"ffiminer_sup{sup_int}.out\"\n",
    "        err_path = self.logs_dir / f\"ffiminer_sup{sup_int}.err\"\n",
    "\n",
    "        cmd = [\n",
    "            sys.executable, \"-m\", \"src.algorithms.fuzzy.ffiminer\",\n",
    "            str(self.paths[\"fixed_text\"]), str(int(sup_int)), \"-o\", str(patterns_path),\n",
    "        ]\n",
    "        self._run_subprocess(cmd, log_path, err_path)\n",
    "\n",
    "    def run_all_experiments(self, supports: List[int], \n",
    "                            cuffi_params: Dict[str, Any], force: bool = False):\n",
    "        \"\"\"Orchestrates running all miners for all specified supports.\"\"\"\n",
    "        \n",
    "        cpu_supports: Set[int] = set(sorted(supports, reverse=True)[:1])\n",
    "\n",
    "        for sup in supports:\n",
    "            # 1. cuFFIMiner\n",
    "            cuffi_log = self.logs_dir / f\"cuffi_sup{sup}.out\"\n",
    "            if (not cuffi_log.exists()) or force:\n",
    "                self.run_cuffi(sup, cuffi_params)\n",
    "            else:\n",
    "                print(f\"[skip] cuFFI sup={sup} (log exists)\")\n",
    "\n",
    "            # 2. naiveFFIMiner (floating)\n",
    "            naive_flt_log = self.logs_dir / f\"naive_floating_sup{sup}.out\"\n",
    "            legacy_naive_log = self.logs_dir / f\"naive_sup{sup}.out\"\n",
    "            if (not naive_flt_log.exists() and not legacy_naive_log.exists()) or force:\n",
    "                    self.run_naive_floating(sup)\n",
    "            else:\n",
    "                print(f\"[skip] naive (floating) sup={sup} (log exists)\")\n",
    "\n",
    "            # 3. naiveFFIMiner (fixed)\n",
    "            naive_fix_log = self.logs_dir / f\"naive_fixed_sup{sup}.out\"\n",
    "            if (not naive_fix_log.exists()) or force:\n",
    "                self.run_naive_fixed(sup, 1)\n",
    "            else:\n",
    "                print(f\"[skip] naive (fixed) sup={sup} (log exists)\")\n",
    "\n",
    "            # 4. CPU Miners (Top 1 largest support only)\n",
    "            if sup in cpu_supports:\n",
    "                ffi_log = self.logs_dir / f\"ffiminer_sup{sup}.out\"\n",
    "                if (not ffi_log.exists()) or force:\n",
    "                    print(f\"[info] Running ffiMiner for sup={sup}...\")\n",
    "                    self.run_ffiminer(sup)\n",
    "                else:\n",
    "                    print(f\"[skip] ffiMiner sup={sup} (log exists)\")\n",
    "        \n",
    "        print(\"[run] All experiments complete.\")\n",
    "\n",
    "\n",
    "class ResultsCollector:\n",
    "    \"\"\"\n",
    "    Parses all log files, collects metrics, and saves to a CSV.\n",
    "    \"\"\"\n",
    "    _METRIC_PATTERNS = {\n",
    "        \"exec_time\":      re.compile(r\"Execution Time:\\s*([0-9.]+)\\s*seconds\", re.I),\n",
    "        \"cpu_mem_mb\":     re.compile(r\"(?:Peak\\s+)?CPU Memory(?: Usage)?:\\s*([0-9.]+)\\s*MB\", re.I),\n",
    "        \"gpu_mem_mb\":     re.compile(r\"Peak GPU \\(driver\\) Used:\\s*([0_9.]+)\\s*MB\", re.I),\n",
    "        \"patterns_found\": re.compile(r\"^(?:Total\\s+)?Patterns Found:\\s*(\\d+)$\", re.I | re.M)\n",
    "    }\n",
    "    \n",
    "    _RUN_CONFIGS = [\n",
    "        (\"cuFFIMiner\",             f\"cuffi_sup{{sup}}.out\"),\n",
    "        (\"naiveFFIMiner_floating\", f\"naive_floating_sup{{sup}}.out\"),\n",
    "        # (\"naiveFFIMiner_fixed\",    f\"naive_fixed_sup{{sup}}.out\"),\n",
    "        (\"ffiMiner\",               f\"ffiminer_sup{{sup}}.out\"),\n",
    "    ]\n",
    "\n",
    "    def __init__(self, dataset_name: str, sf: int, quant_mult: int, \n",
    "                 supports: List[int], ds_dir: Path):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.sf = sf\n",
    "        self.quant_mult = quant_mult\n",
    "        self.supports = supports\n",
    "        self.ds_dir = ds_dir\n",
    "        self.logs_dir = self.ds_dir / \"logs\"\n",
    "\n",
    "    def _parse_metrics_from_log(self, log_path: Path) -> Dict[str, Optional[float]]:\n",
    "        text = log_path.read_text(errors=\"ignore\")\n",
    "        out: Dict[str, Optional[float]] = {}\n",
    "        for k, rgx in self._METRIC_PATTERNS.items():\n",
    "            m = rgx.search(text)\n",
    "            # Handle potential underscores in numbers\n",
    "            out[k] = float(m.group(1).replace('_', '')) if m else None\n",
    "        return out\n",
    "\n",
    "    def collect(self) -> pd.DataFrame:\n",
    "        \"\"\"Collects all metrics from all logs into a single DataFrame.\"\"\"\n",
    "        rows: List[Dict[str, Any]] = []\n",
    "\n",
    "        for sup in self.supports:\n",
    "            for algo_name, log_template in self._RUN_CONFIGS:\n",
    "                log_filename = log_template.format(sup=sup)\n",
    "                log_path = self.logs_dir / log_filename\n",
    "\n",
    "                if not log_path.exists() and algo_name == \"cuFFIMiner\":\n",
    "                    alt = self.ds_dir / log_filename\n",
    "                    if alt.exists(): log_path = alt\n",
    "                if not log_path.exists() and algo_name == \"naiveFFIMiner_floating\":\n",
    "                    old = self.logs_dir / f\"naive_sup{sup}.out\"\n",
    "                    if old.exists(): log_path = old\n",
    "            \n",
    "                if log_path.exists():\n",
    "                    print(f\"[collect] Parsing {log_path.name}\")\n",
    "                    m = self._parse_metrics_from_log(log_path)\n",
    "                    final_algo_name = algo_name.replace(\"_floating\", \" (floating)\").replace(\"_fixed\", \" (fixed)\")\n",
    "                    rows.append({\n",
    "                        \"dataset\": self.dataset_name, \"sf\": self.sf, \n",
    "                        \"algorithm\": final_algo_name,\n",
    "                        \"support_quant_int\": sup, \"quant_mult\": self.quant_mult,\n",
    "                        **m\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"[collect] Skipping {algo_name} (sup={sup}): log not found.\")\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def collect_and_save(self) -> pd.DataFrame:\n",
    "        \"\"\"Collects metrics, saves to CSV, and returns the DataFrame.\"\"\"\n",
    "        df = self.collect()\n",
    "        if df.empty:\n",
    "            print(\"[collect] No data collected, DataFrame is empty.\")\n",
    "            return df\n",
    "            \n",
    "        metrics_csv = self.ds_dir / f\"metrics_SF{self.sf}.csv\"\n",
    "        df.to_csv(metrics_csv, index=False)\n",
    "        print(f\"[collect] Metrics saved to {metrics_csv}\")\n",
    "        return df\n",
    "\n",
    "\n",
    "class PlotGenerator:\n",
    "    \"\"\"\n",
    "    Generates static image plots (JPG) using Matplotlib.\n",
    "    \"\"\"\n",
    "    _LABELS = {\n",
    "        \"exec_time\": \"Execution Time (s)\",\n",
    "        \"patterns_found\": \"Patterns Found\",\n",
    "    }\n",
    "    \n",
    "    _ALGO_ORDER = [\"cuFFIMiner\", \"naiveFFIMiner (floating)\", \"naiveFFIMiner (fixed)\", \"ffiMiner\"]\n",
    "    _COLORS = {\"cuFFIMiner\": \"C0\", \"naiveFFIMiner (floating)\": \"C1\", \"naiveFFIMiner (fixed)\": \"C2\", \"ffiMiner\": \"C3\"}\n",
    "    _MARKERS = {\"cuFFIMiner\": \"o\", \"naiveFFIMiner (floating)\": \"o\", \"naiveFFIMiner (fixed)\": \"x\", \"ffiMiner\": \"s\"}\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, dataset_name: str, sf: int, ds_dir: Path):\n",
    "        self.df = df\n",
    "        self.dataset_name = dataset_name\n",
    "        self.sf = sf\n",
    "        self.jpg_figs_dir = ds_dir / \"figures_jpg\"\n",
    "        self.jpg_figs_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Configure Matplotlib for small, high-DPI plots\n",
    "        plt.rcParams.update({\n",
    "            \"backend\": \"agg\", # Use non-interactive backend for scripts\n",
    "            \"pdf.fonttype\": 42,\n",
    "            \"ps.fonttype\": 42,\n",
    "            \"figure.dpi\": 500,\n",
    "            \"font.size\": 8,\n",
    "            \"axes.titlesize\": 8,\n",
    "            \"axes.labelsize\": 7,\n",
    "            \"xtick.labelsize\": 7,\n",
    "            \"ytick.labelsize\": 7,\n",
    "            \"legend.fontsize\": 6, # Small legend\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def pretty_names(self):\n",
    "        # Use pretty names for plot legend\n",
    "        return {\n",
    "            \"cuFFIMiner\": \"cuFFPM\",\n",
    "            \"naiveFFIMiner (floating)\": \"Naive\",\n",
    "            \"naiveFFIMiner (fixed)\": \"Naive (Fixed)\",\n",
    "            \"ffiMiner\": \"FFI-M\"\n",
    "        }\n",
    "\n",
    "    def _save_jpg_plot(self, metric: str):\n",
    "        \"\"\"Generates and saves a single JPG plot WITHOUT a legend.\"\"\"\n",
    "        if metric not in self.df.columns: return\n",
    "        dfm = self.df.dropna(subset=[metric])\n",
    "        if dfm.empty: return\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(1, 1)) # Small figure size\n",
    "        \n",
    "        for algo in self._ALGO_ORDER:\n",
    "            sub = dfm[dfm[\"algorithm\"] == algo]\n",
    "            if not sub.empty:\n",
    "                sub = sub.sort_values(\"support_quant_int\")\n",
    "                ax.plot(sub[\"support_quant_int\"].values, sub[metric].values, \n",
    "                        marker=self._MARKERS.get(algo, \".\"), \n",
    "                        color=self._COLORS.get(algo),\n",
    "                        markersize=3, \n",
    "                        linewidth=1)\n",
    "                        \n",
    "        ax.set_xlabel(\"Support Threshold\")\n",
    "        ax.set_ylabel(self._LABELS.get(metric, metric))\n",
    "        \n",
    "        ax.set_xscale(\"log\", base=10)\n",
    "        ax.set_yscale(\"log\", base=10)\n",
    "        \n",
    "        ax.grid(alpha=0.25, linestyle=\":\")\n",
    "        fig.tight_layout(pad=0.1)\n",
    "        \n",
    "        jpg_path = self.jpg_figs_dir / f\"{self.dataset_name}_{metric}_SF{self.sf}.jpg\"\n",
    "        fig.savefig(jpg_path, format=\"jpg\", dpi=500, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"[plot] wrote JPG: {jpg_path}\")\n",
    "\n",
    "    def generate_jpg_legend(self):\n",
    "        \"\"\"Generates a standalone JPG image for the legend.\"\"\"\n",
    "        \n",
    "        legend_handles = []\n",
    "        legend_labels = []\n",
    "\n",
    "        for algo in self._ALGO_ORDER:\n",
    "            line = plt.Line2D([], [], color=self._COLORS.get(algo), \n",
    "                              marker=self._MARKERS.get(algo, '.'), \n",
    "                              markersize=3, linewidth=1, linestyle='None')\n",
    "            legend_handles.append(line)\n",
    "            legend_labels.append(self.pretty_names.get(algo, algo))\n",
    "\n",
    "        fig_legend = plt.figure(figsize=(4.0, 0.5))\n",
    "        ax_legend = fig_legend.add_subplot(111)\n",
    "\n",
    "        legend = ax_legend.legend(legend_handles, legend_labels, \n",
    "                                  loc='center', ncol=len(legend_labels),\n",
    "                                  frameon=False, fontsize=6)\n",
    "        \n",
    "        ax_legend.set_axis_off()\n",
    "        fig_legend.tight_layout(pad=0.1)\n",
    "\n",
    "        legend_path = self.jpg_figs_dir / f\"legend_SF{self.sf}.jpg\"\n",
    "        fig_legend.savefig(legend_path, format=\"jpg\", dpi=500, bbox_inches='tight')\n",
    "        plt.close(fig_legend)\n",
    "        print(f\"[plot] wrote JPG legend: {legend_path}\")\n",
    "\n",
    "    def generate_all_jpg_plots(self, metrics: Optional[List[str]] = None):\n",
    "        \"\"\"Generates .jpg files for all specified metrics and a separate legend.\"\"\"\n",
    "        ms = metrics or [\"exec_time\", \"patterns_found\"]\n",
    "        for m in ms:\n",
    "            self._save_jpg_plot(m)\n",
    "        self.generate_jpg_legend()\n",
    "        print(\"[plot] JPG plot generation done.\")\n",
    "\n",
    "\n",
    "class MatplotlibPGFGenerator:\n",
    "    \"\"\"\n",
    "    Generates static PGF plots using Matplotlib's PGF backend.\n",
    "    \"\"\"\n",
    "    _LABELS = {\n",
    "        \"exec_time\": \"Execution Time (s)\",\n",
    "        \"patterns_found\": \"Patterns Found\",\n",
    "    }\n",
    "    \n",
    "    _ALGO_ORDER = [\"cuFFIMiner\", \"naiveFFIMiner (floating)\", \"naiveFFIMiner (fixed)\", \"ffiMiner\"]\n",
    "    _COLORS = {\"cuFFIMiner\": \"C0\", \"naiveFFIMiner (floating)\": \"C1\", \"naiveFFIMiner (fixed)\": \"C2\", \"ffiMiner\": \"C3\"}\n",
    "    _MARKERS = {\"cuFFIMiner\": \"o\", \"naiveFFIMiner (floating)\": \"o\", \"naiveFFIMiner (fixed)\": \"x\", \"ffiMiner\": \"s\"}\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, dataset_name: str, sf: int, ds_dir: Path):\n",
    "        self.df = df\n",
    "        self.dataset_name = dataset_name\n",
    "        self.sf = sf\n",
    "        self.pgf_figs_dir = ds_dir / \"figures_pgf\"\n",
    "        self.pgf_figs_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Configure Matplotlib for PGF backend\n",
    "        plt.rcParams.update({\n",
    "            \"backend\": \"pgf\",\n",
    "            \"font.family\": \"serif\", # Use document font\n",
    "            \"font.size\": 8,\n",
    "            \"axes.labelsize\": 7,\n",
    "            \"xtick.labelsize\": 7,\n",
    "            \"ytick.labelsize\": 7,\n",
    "            \"legend.fontsize\": 6,\n",
    "            \"pgf.texsystem\": \"pdflatex\",\n",
    "            \"pgf.preamble\": (\n",
    "                r\"\\usepackage[utf8x]{inputenc}\"\n",
    "                r\"\\usepackage[T1]{fontenc}\"\n",
    "                r\"\\usepackage{amssymb}\" # For markers\n",
    "            ),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def pretty_names(self):\n",
    "        return {\n",
    "            \"cuFFIMiner\": \"cuFFPM\",\n",
    "            \"naiveFFIMiner (floating)\": \"Naive\",\n",
    "            \"naiveFFIMiner (fixed)\": \"Naive (Fixed)\",\n",
    "            \"ffiMiner\": \"FFI-M\"\n",
    "        }\n",
    "\n",
    "    def _save_pgf_plot(self, metric: str):\n",
    "        \"\"\"Generates and saves a single PGF plot WITHOUT a legend.\"\"\"\n",
    "        if metric not in self.df.columns: return\n",
    "        dfm = self.df.dropna(subset=[metric])\n",
    "        if dfm.empty: return\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(2, 2)) \n",
    "        \n",
    "        for algo in self._ALGO_ORDER:\n",
    "            sub = dfm[dfm[\"algorithm\"] == algo]\n",
    "            if not sub.empty:\n",
    "                sub = sub.sort_values(\"support_quant_int\")\n",
    "                ax.plot(sub[\"support_quant_int\"].values, sub[metric].values, \n",
    "                        marker=self._MARKERS.get(algo, \".\"), \n",
    "                        color=self._COLORS.get(algo),\n",
    "                        markersize=3, \n",
    "                        linewidth=1)\n",
    "                        \n",
    "        ax.set_xlabel(\"Support Threshold\")\n",
    "        ax.set_ylabel(self._LABELS.get(metric, metric))\n",
    "        \n",
    "        ax.set_xscale(\"log\", base=10)\n",
    "        ax.set_yscale(\"log\", base=10)\n",
    "        \n",
    "        ax.grid(alpha=0.25, linestyle=\":\")\n",
    "        fig.tight_layout(pad=0.05)\n",
    "        \n",
    "        pgf_path = self.pgf_figs_dir / f\"{self.dataset_name}_{metric}_SF{self.sf}.pgf\"\n",
    "        fig.savefig(pgf_path, format=\"pgf\", bbox_inches='tight', pad_inches=0.05)\n",
    "        plt.close(fig)\n",
    "        print(f\"[plot] wrote PGF: {pgf_path}\")\n",
    "\n",
    "    def generate_pgf_legend(self):\n",
    "        \"\"\"Generates a standalone PGF image for the legend.\"\"\"\n",
    "        \n",
    "        legend_handles = []\n",
    "        legend_labels = []\n",
    "\n",
    "        for algo in self._ALGO_ORDER:\n",
    "            line = plt.Line2D([], [], color=self._COLORS.get(algo), \n",
    "                              marker=self._MARKERS.get(algo, '.'), \n",
    "                              markersize=3, linewidth=1, linestyle='None')\n",
    "            legend_handles.append(line)\n",
    "            legend_labels.append(self.pretty_names.get(algo, algo))\n",
    "\n",
    "        fig_legend = plt.figure(figsize=(4.0, 0.5))\n",
    "        ax_legend = fig_legend.add_subplot(111)\n",
    "\n",
    "        legend = ax_legend.legend(legend_handles, legend_labels, \n",
    "                                  loc='center', ncol=len(legend_labels),\n",
    "                                  frameon=False, fontsize=6)\n",
    "        \n",
    "        ax_legend.set_axis_off()\n",
    "        fig_legend.tight_layout(pad=0)\n",
    "\n",
    "        legend_path = self.pgf_figs_dir / f\"legend_SF{self.sf}.pgf\"\n",
    "        fig_legend.savefig(legend_path, format=\"pgf\", bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig_legend)\n",
    "        print(f\"[plot] wrote PGF legend: {legend_path}\")\n",
    "\n",
    "    def generate_all_pgf_plots(self, metrics: Optional[List[str]] = None):\n",
    "        \"\"\"Generates .pgf files for all metrics and a separate legend.\"\"\"\n",
    "        ms = metrics or [\"exec_time\", \"patterns_found\"]\n",
    "        for m in ms:\n",
    "            self._save_pgf_plot(m)\n",
    "        self.generate_pgf_legend()\n",
    "        print(\"[plot] PGF plot generation done.\")\n",
    "\n",
    "\n",
    "class LatexGenerator:\n",
    "    \"\"\"\n",
    "    Generates LaTeX files: tables and figure wrappers.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, dataset_name: str, sf: int, ds_dir: Path):\n",
    "        self.df = df\n",
    "        self.dataset_name = dataset_name\n",
    "        self.sf = sf\n",
    "        self.ds_dir = ds_dir\n",
    "        self.pgf_figs_dir = self.ds_dir / \"figures_pgf\" \n",
    "\n",
    "    def _format_sci_latex(self, n: float) -> str:\n",
    "        \"\"\"Helper for formatting table numbers.\"\"\"\n",
    "        if n == 0: return \"$0$\"\n",
    "        if not pd.notna(n): return \"---\"\n",
    "        \n",
    "        exponent = int(math.floor(math.log10(abs(n))))\n",
    "        mantissa = n / (10**exponent)\n",
    "        \n",
    "        if mantissa == 1.0:\n",
    "            return f\"$1 \\\\times 10^{{{exponent}}}$\"\n",
    "        else:\n",
    "            return f\"${mantissa:.1f} \\\\times 10^{{{exponent}}}$\"\n",
    "\n",
    "    def generate_latex_tables(self):\n",
    "        \"\"\"Generates a .tex file containing the results subtable.\"\"\"\n",
    "        \n",
    "        table_algo_order = [\"cuFFIMiner\", \"naiveFFIMiner (floating)\", \"ffiMiner\"]\n",
    "        table_pretty_names = {\n",
    "            \"cuFFIMiner\": \"cuFFPM\",\n",
    "            \"naiveFFIMiner (floating)\": \"Naive\",\n",
    "            \"ffiMiner\": \"FFI-M\"\n",
    "        }\n",
    "        \n",
    "        available_algos = [a for a in table_algo_order if a in self.df['algorithm'].unique()]\n",
    "        num_algos = len(available_algos)\n",
    "\n",
    "        if num_algos == 0:\n",
    "            print(\"[latex] No algorithms found in data. Skipping table generation.\")\n",
    "            return\n",
    "            \n",
    "        output = [f\"% --- LaTeX Table for {self.dataset_name} (SF={self.sf}) ---\"]\n",
    "        \n",
    "        try:\n",
    "            df_time = self.df.pivot(index=\"support_quant_int\", columns=\"algorithm\", values=\"exec_time\")\n",
    "            df_time = df_time[available_algos].rename(columns=table_pretty_names)\n",
    "            df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
    "            df_time.columns = pd.MultiIndex.from_product([['Time (s)'], df_time.columns])\n",
    "\n",
    "            df_patterns = self.df.pivot(index=\"support_quant_int\", columns=\"algorithm\", values=\"patterns_found\")\n",
    "            df_patterns = df_patterns[available_algos].rename(columns=table_pretty_names)\n",
    "            df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n",
    "            df_patterns.columns = pd.MultiIndex.from_product([['Patterns'], df_patterns.columns])\n",
    "\n",
    "            df_combined = pd.concat([df_time, df_patterns], axis=1).sort_index(ascending=False)\n",
    "            \n",
    "            df_combined = df_combined.reset_index()\n",
    "            df_combined['support_quant_int'] = df_combined['support_quant_int'].apply(self._format_sci_latex)\n",
    "            df_combined = df_combined.set_index('support_quant_int')\n",
    "            df_combined.index.name = \"MinSup\" \n",
    "\n",
    "            col_format = f\"l{'r' * num_algos}{'r' * num_algos}\"\n",
    "            latex_tabular = df_combined.to_latex(\n",
    "                index=True, header=True, na_rep=\"---\", column_format=col_format,\n",
    "                multicolumn=True, escape=False\n",
    "            )\n",
    "\n",
    "            col_start_time = 2\n",
    "            col_end_time = col_start_time + num_algos - 1\n",
    "            col_start_patterns = col_end_time + 1\n",
    "            col_end_patterns = col_start_patterns + num_algos - 1\n",
    "            cmid_rule = f\"\\\\cmidrule(lr){{{col_start_time}-{col_end_time}}} \\\\cmidrule(lr){{{col_start_patterns}-{col_end_patterns}}}\"\n",
    "\n",
    "            lines = latex_tabular.split('\\n')\n",
    "            lines.insert(3, cmid_rule)\n",
    "            latex_tabular_with_cmid = \"\\n\".join(lines)\n",
    "\n",
    "            subtable_caption = f\"{self.dataset_name} (SF={self.sf})\"\n",
    "            subtable_label = f\"tab:{self.dataset_name}_sf{self.sf}\"\n",
    "            final_latex = f\"\"\"\\\\begin{{subtable}}{{\\\\linewidth}}\n",
    "\\\\centering\n",
    "\\\\caption{{{subtable_caption}}}\n",
    "\\\\label{{{subtable_label}}}\n",
    "{latex_tabular_with_cmid}\n",
    "\\\\end{{subtable}}%\"\"\"\n",
    "            output.append(final_latex)\n",
    "            \n",
    "        except Exception as e:\n",
    "            output.append(f\"% Could not generate combined table for {self.dataset_name}: {e}\")\n",
    "\n",
    "        output.append(f\"% --- End LaTeX Table ---\")\n",
    "        \n",
    "        latex_path = self.ds_dir / f\"tables_SF{self.sf}.tex\"\n",
    "        latex_path.write_text(\"\\n\".join(output))\n",
    "        print(f\"[latex] Generated LaTeX table: {latex_path}\")\n",
    "\n",
    "    def generate_latex_figures(self):\n",
    "        \"\"\"Generates a .tex file that wraps the .pgf plots in a 'figure' env.\"\"\"\n",
    "        output = [\n",
    "            f\"% --- LaTeX Figures for {self.dataset_name} (SF={self.sf}) ---\",\n",
    "            f\"% Requires: \\\\usepackage{{pgf}}, \\\\usepackage{{subcaption}}\",\n",
    "        ]\n",
    "\n",
    "        time_pgf = self.pgf_figs_dir / f\"{self.dataset_name}_exec_time_SF{self.sf}.pgf\"\n",
    "        patterns_pgf = self.pgf_figs_dir / f\"{self.dataset_name}_patterns_found_SF{self.sf}.pgf\"\n",
    "        legend_pgf = self.pgf_figs_dir / f\"legend_SF{self.sf}.pgf\"\n",
    "\n",
    "        time_pgf_path_latex = f\"{self.pgf_figs_dir.name}/{time_pgf.name}\"\n",
    "        patterns_pgf_path_latex = f\"{self.pgf_figs_dir.name}/{patterns_pgf.name}\"\n",
    "        legend_pgf_path_latex = f\"{self.pgf_figs_dir.name}/{legend_pgf.name}\"\n",
    "\n",
    "        has_time_plot = time_pgf.exists()\n",
    "        has_patterns_plot = patterns_pgf.exists()\n",
    "\n",
    "        if not has_time_plot and not has_patterns_plot:\n",
    "            print(f\"[latex] No .pgf plots found in {self.pgf_figs_dir}. Skipping figure wrapper.\")\n",
    "            return\n",
    "\n",
    "        figure_caption = f\"Performance and pattern count for {self.dataset_name} (SF={self.sf}).\"\n",
    "        figure_label = f\"fig:{self.dataset_name}_sf{self.sf}\"\n",
    "        subfig_width = \"0.49\\\\linewidth\"\n",
    "\n",
    "        latex_content = f\"\"\"\\\\begin{{figure}}[tbh!]\n",
    "    \\\\centering\n",
    "    % Input the standalone PGF legend\n",
    "    \\\\input{{{legend_pgf_path_latex}}}\n",
    "    \\\\caption{{{figure_caption}}}\n",
    "    \\\\label{{{figure_label}}}\n",
    "\"\"\"\n",
    "\n",
    "        if has_time_plot:\n",
    "            latex_content += f\"\"\"\n",
    "    \\\\begin{{subfigure}}[b]{{{subfig_width}}}\n",
    "        \\\\centering\n",
    "        % Input the PGF file directly\n",
    "        \\\\input{{{time_pgf_path_latex}}}\n",
    "        \\\\caption{{Execution Time}}\n",
    "        \\\\label{{{figure_label}_time}}\n",
    "    \\\\end{{subfigure}}\"\"\"\n",
    "        \n",
    "        if has_time_plot and has_patterns_plot:\n",
    "            latex_content += \"\\n    \\\\hfill % Separator\\n\"\n",
    "\n",
    "        if has_patterns_plot:\n",
    "            latex_content += f\"\"\"\n",
    "    \\\\begin{{subfigure}}[b]{{{subfig_width}}}\n",
    "        \\\\centering\n",
    "        % Input the PGF file directly\n",
    "        \\\\input{{{patterns_pgf_path_latex}}}\n",
    "        \\\\caption{{Patterns Found}}\n",
    "        \\\\label{{{figure_label}_patterns}}\n",
    "    \\\\end{{subfigure}}\"\"\"\n",
    "\n",
    "        latex_content += \"\\n\\\\end{figure}\"\n",
    "        output.append(latex_content)\n",
    "        output.append(f\"% --- End LaTeX Figures ---\")\n",
    "        \n",
    "        latex_path = self.ds_dir / f\"figures_SF{self.sf}.tex\"\n",
    "        latex_path.write_text(\"\\n\".join(output))\n",
    "        print(f\"[latex] Generated LaTeX figures wrapper: {latex_path}\")\n",
    "\n",
    "    def generate_all(self):\n",
    "        \"\"\"Generates all LaTeX files (tables and wrappers).\"\"\"\n",
    "        if self.df.empty:\n",
    "            print(\"[latex] DataFrame is empty, skipping all file generation.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"[latex] Generating all LaTeX outputs for {self.dataset_name} (SF={self.sf})...\")\n",
    "        self.generate_latex_tables()\n",
    "        self.generate_latex_figures()\n",
    "        print(f\"[latex] All LaTeX outputs generated in {self.ds_dir}\")\n",
    "\n",
    "\n",
    "class Orchestrator:\n",
    "    \"\"\"\n",
    "    Wires all pipeline components together and runs the full process.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: Dict[str, Any], project_root: Path, \n",
    "                 data_dir: Path, results_dir: Path):\n",
    "        self.config = config\n",
    "        self.project_root = project_root\n",
    "        self.data_dir = data_dir\n",
    "        self.results_dir = results_dir\n",
    "        \n",
    "        self.url = config[\"url\"]\n",
    "        self.sf = config[\"sf\"]\n",
    "        self.supports = config[\"supports\"]\n",
    "        self.cuffi_params = config.get(\"cuffi_params\", {})\n",
    "        self.force_run = config.get(\"force_run\", False)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Executes the full prep -> run -> collect -> plot (jpg+pgf) -> latex pipeline.\"\"\"\n",
    "        print(f\"--- üöÄ Starting Pipeline for {self.url} (SF={self.sf}) ---\")\n",
    "        \n",
    "        # 1. Prep\n",
    "        print(\"--- 1. Preparing Dataset ---\")\n",
    "        preparer = DatasetPreparer(self.project_root, self.data_dir)\n",
    "        paths, quant_mult, dataset_name = preparer.prepare(self.url, self.sf)\n",
    "        \n",
    "        ds_dir = self.results_dir / dataset_name / f\"SF{self.sf}\"\n",
    "        ds_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 2. Run\n",
    "        print(\"--- 2. Running Experiments ---\")\n",
    "        runner = ExperimentRunner(self.project_root, ds_dir, paths, quant_mult)\n",
    "        runner.run_all_experiments(self.supports, self.cuffi_params, self.force_run)\n",
    "\n",
    "        # 3. Collect\n",
    "        print(\"--- 3. Collecting Results ---\")\n",
    "        collector = ResultsCollector(dataset_name, self.sf, quant_mult, self.supports, ds_dir)\n",
    "        df = collector.collect_and_save()\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"--- ‚ö†Ô∏è Pipeline Halting: No results were collected. ---\")\n",
    "            return None\n",
    "\n",
    "        # 4. Generate JPG Plots\n",
    "        print(\"--- 4. Generating JPG Plots (using Matplotlib) ---\")\n",
    "        plot_gen = PlotGenerator(df, dataset_name, self.sf, ds_dir)\n",
    "        plot_gen.generate_all_jpg_plots()\n",
    "\n",
    "        # 5. Generate PGF Plots\n",
    "        print(\"--- 5. Generating PGF Plots (using Matplotlib) ---\")\n",
    "        # This will reconfigure plt.rcParams for PGF\n",
    "        pgf_plot_gen = MatplotlibPGFGenerator(df, dataset_name, self.sf, ds_dir)\n",
    "        pgf_plot_gen.generate_all_pgf_plots()\n",
    "\n",
    "        # 6. Generate LaTeX Outputs (Tables and Figure Wrappers)\n",
    "        print(\"--- 6. Generating LaTeX Outputs ---\")\n",
    "        latex_gen = LatexGenerator(df, dataset_name, self.sf, ds_dir)\n",
    "        latex_gen.generate_all()\n",
    "\n",
    "        print(f\"--- ‚úÖ Pipeline Complete for {dataset_name} (SF={self.sf}) ---\")\n",
    "        return df\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# High-level functional wrapper\n",
    "# ----------------------------------------\n",
    "def run_pipeline(\n",
    "    dataset_url: str, \n",
    "    sf: int, \n",
    "    supports_quant_int: List[int], *,\n",
    "    cuffi_params: Optional[Dict[str, Any]] = None,\n",
    "    force: bool = False\n",
    ") -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    High-level functional wrapper to run the entire pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    if cuffi_params is None:\n",
    "        cuffi_params = {\n",
    "            \"allocator\": \"rmm_device\",\n",
    "            \"gds\": \"off\",\n",
    "        }\n",
    "\n",
    "    pipeline_config = {\n",
    "        \"url\": dataset_url,\n",
    "        \"sf\": sf,\n",
    "        \"supports\": supports_quant_int,\n",
    "        \"cuffi_params\": cuffi_params,\n",
    "        \"force_run\": force\n",
    "    }\n",
    "\n",
    "    print(f\"--- üöÄ Starting Pipeline for {dataset_url} (SF={sf}) ---\")\n",
    "    print(f\"Supports: {supports_quant_int}\")\n",
    "\n",
    "    try:\n",
    "        orchestrator = Orchestrator(\n",
    "            config=pipeline_config,\n",
    "            project_root=PROJECT_ROOT,\n",
    "            data_dir=DATA_DIR,\n",
    "            results_dir=RESULTS_DIR\n",
    "        )\n",
    "        results_df = orchestrator.run()\n",
    "        \n",
    "        if results_df is not None:\n",
    "            print(f\"--- ‚úÖ Pipeline Complete for {dataset_url} (SF={sf}) ---\")\n",
    "        else:\n",
    "            print(f\"--- ‚ö†Ô∏è Pipeline Finished (no results) for {dataset_url} (SF={sf}) ---\")\n",
    "            \n",
    "        return results_df\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"\\n[ERROR] Failed to import a script: {e}\", file=sys.stderr)\n",
    "        print(\"Please ensure your PYTHONPATH is correct and all dependencies are installed.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] An unexpected error occurred during SF={sf} run: {e}\", file=sys.stderr)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fb90bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv (SF=1) ---\n",
      "Supports: [80, 90, 100, 110, 1000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv (SF=1) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail.csv\n",
      "[prep] Using existing: Fuzzy_retail_SF1.csv\n",
      "Processing Fuzzy_retail_SF1.csv...\n",
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF1_fixed_10.csv...\n",
      "[convert] method=cudf rows=1256571 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF1_fixed_10.parquet\n",
      "[convert] method=cudf rows=1256571 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF1.parquet\n",
      "[prep] Dataset 'Fuzzy_retail' (SF=1) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=80 (log exists)\n",
      "[skip] naive (floating) sup=80 (log exists)\n",
      "[skip] naive (fixed) sup=80 (log exists)\n",
      "[skip] cuFFI sup=90 (log exists)\n",
      "[skip] naive (floating) sup=90 (log exists)\n",
      "[skip] naive (fixed) sup=90 (log exists)\n",
      "[skip] cuFFI sup=100 (log exists)\n",
      "[skip] naive (floating) sup=100 (log exists)\n",
      "[skip] naive (fixed) sup=100 (log exists)\n",
      "[skip] cuFFI sup=110 (log exists)\n",
      "[skip] naive (floating) sup=110 (log exists)\n",
      "[skip] naive (fixed) sup=110 (log exists)\n",
      "[skip] cuFFI sup=1000 (log exists)\n",
      "[skip] naive (floating) sup=1000 (log exists)\n",
      "[skip] naive (fixed) sup=1000 (log exists)\n",
      "[skip] ffiMiner sup=1000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup80.out\n",
      "[collect] Parsing naive_floating_sup80.out\n",
      "[collect] Skipping ffiMiner (sup=80): log not found.\n",
      "[collect] Parsing cuffi_sup90.out\n",
      "[collect] Parsing naive_floating_sup90.out\n",
      "[collect] Skipping ffiMiner (sup=90): log not found.\n",
      "[collect] Parsing cuffi_sup100.out\n",
      "[collect] Parsing naive_floating_sup100.out\n",
      "[collect] Skipping ffiMiner (sup=100): log not found.\n",
      "[collect] Parsing cuffi_sup110.out\n",
      "[collect] Parsing naive_floating_sup110.out\n",
      "[collect] Skipping ffiMiner (sup=110): log not found.\n",
      "[collect] Parsing cuffi_sup1000.out\n",
      "[collect] Parsing naive_floating_sup1000.out\n",
      "[collect] Parsing ffiminer_sup1000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/metrics_SF1.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_jpg/Fuzzy_retail_exec_time_SF1.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_jpg/Fuzzy_retail_patterns_found_SF1.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_jpg/legend_SF1.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_pgf/Fuzzy_retail_exec_time_SF1.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_pgf/Fuzzy_retail_patterns_found_SF1.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_pgf/legend_SF1.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_retail (SF=1)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/tables_SF1.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1/figures_SF1.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF1\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_retail (SF=1) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv (SF=1) ---\n",
      "         dataset  sf                 algorithm  support_quant_int  quant_mult  \\\n",
      "0   Fuzzy_retail   1                cuFFIMiner                 80          10   \n",
      "1   Fuzzy_retail   1  naiveFFIMiner (floating)                 80          10   \n",
      "2   Fuzzy_retail   1                cuFFIMiner                 90          10   \n",
      "3   Fuzzy_retail   1  naiveFFIMiner (floating)                 90          10   \n",
      "4   Fuzzy_retail   1                cuFFIMiner                100          10   \n",
      "5   Fuzzy_retail   1  naiveFFIMiner (floating)                100          10   \n",
      "6   Fuzzy_retail   1                cuFFIMiner                110          10   \n",
      "7   Fuzzy_retail   1  naiveFFIMiner (floating)                110          10   \n",
      "8   Fuzzy_retail   1                cuFFIMiner               1000          10   \n",
      "9   Fuzzy_retail   1  naiveFFIMiner (floating)               1000          10   \n",
      "10  Fuzzy_retail   1                  ffiMiner               1000          10   \n",
      "\n",
      "    exec_time  cpu_mem_mb gpu_mem_mb  patterns_found  \n",
      "0      1.8524     1009.30       None        136556.0  \n",
      "1      0.9670     1009.30       None         41206.0  \n",
      "2      1.5886     1009.30       None        114415.0  \n",
      "3      0.7732     1009.30       None         35202.0  \n",
      "4      1.7115     1009.30       None         98151.0  \n",
      "5      0.8164     1009.30       None         30643.0  \n",
      "6      1.5146     1009.30       None         85504.0  \n",
      "7      0.7026     1009.30       None         27127.0  \n",
      "8      1.1762     1009.30       None          3530.0  \n",
      "9      0.6177     1009.30       None          1907.0  \n",
      "10    10.8199      342.36       None          3530.0  \n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv (SF=10) ---\n",
      "Supports: [800, 900, 1000, 1100, 10000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv (SF=10) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail.csv\n",
      "[prep] Using existing: Fuzzy_retail_SF10.csv\n",
      "Processing Fuzzy_retail_SF10.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF10_fixed_10.csv...\n",
      "[convert] method=cudf rows=12565710 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF10_fixed_10.parquet\n",
      "[convert] method=cudf rows=12565710 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF10.parquet\n",
      "[prep] Dataset 'Fuzzy_retail' (SF=10) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=800 (log exists)\n",
      "[skip] naive (floating) sup=800 (log exists)\n",
      "[skip] naive (fixed) sup=800 (log exists)\n",
      "[skip] cuFFI sup=900 (log exists)\n",
      "[skip] naive (floating) sup=900 (log exists)\n",
      "[skip] naive (fixed) sup=900 (log exists)\n",
      "[skip] cuFFI sup=1000 (log exists)\n",
      "[skip] naive (floating) sup=1000 (log exists)\n",
      "[skip] naive (fixed) sup=1000 (log exists)\n",
      "[skip] cuFFI sup=1100 (log exists)\n",
      "[skip] naive (floating) sup=1100 (log exists)\n",
      "[skip] naive (fixed) sup=1100 (log exists)\n",
      "[skip] cuFFI sup=10000 (log exists)\n",
      "[skip] naive (floating) sup=10000 (log exists)\n",
      "[skip] naive (fixed) sup=10000 (log exists)\n",
      "[skip] ffiMiner sup=10000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup800.out\n",
      "[collect] Parsing naive_floating_sup800.out\n",
      "[collect] Skipping ffiMiner (sup=800): log not found.\n",
      "[collect] Parsing cuffi_sup900.out\n",
      "[collect] Parsing naive_floating_sup900.out\n",
      "[collect] Skipping ffiMiner (sup=900): log not found.\n",
      "[collect] Parsing cuffi_sup1000.out\n",
      "[collect] Parsing naive_floating_sup1000.out\n",
      "[collect] Skipping ffiMiner (sup=1000): log not found.\n",
      "[collect] Parsing cuffi_sup1100.out\n",
      "[collect] Parsing naive_floating_sup1100.out\n",
      "[collect] Skipping ffiMiner (sup=1100): log not found.\n",
      "[collect] Parsing cuffi_sup10000.out\n",
      "[collect] Parsing naive_floating_sup10000.out\n",
      "[collect] Parsing ffiminer_sup10000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/metrics_SF10.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_jpg/Fuzzy_retail_exec_time_SF10.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_jpg/Fuzzy_retail_patterns_found_SF10.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_jpg/legend_SF10.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_pgf/Fuzzy_retail_exec_time_SF10.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_pgf/Fuzzy_retail_patterns_found_SF10.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_pgf/legend_SF10.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_retail (SF=10)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/tables_SF10.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10/figures_SF10.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF10\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_retail (SF=10) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv (SF=10) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sf</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_mb</th>\n",
       "      <th>patterns_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5784</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>136556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>2.1689</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>41169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>900</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5631</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>114415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>900</td>\n",
       "      <td>10</td>\n",
       "      <td>2.1770</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>35185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.4556</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>98151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.1097</td>\n",
       "      <td>2432.10</td>\n",
       "      <td>None</td>\n",
       "      <td>30615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1100</td>\n",
       "      <td>10</td>\n",
       "      <td>2.2112</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>85504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.9540</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>27117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.2986</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>3530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.1328</td>\n",
       "      <td>2409.14</td>\n",
       "      <td>None</td>\n",
       "      <td>1905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>10</td>\n",
       "      <td>ffiMiner</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>189.3511</td>\n",
       "      <td>2380.18</td>\n",
       "      <td>None</td>\n",
       "      <td>3530.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset  sf                 algorithm  support_quant_int  quant_mult  \\\n",
       "0   Fuzzy_retail  10                cuFFIMiner                800          10   \n",
       "1   Fuzzy_retail  10  naiveFFIMiner (floating)                800          10   \n",
       "2   Fuzzy_retail  10                cuFFIMiner                900          10   \n",
       "3   Fuzzy_retail  10  naiveFFIMiner (floating)                900          10   \n",
       "4   Fuzzy_retail  10                cuFFIMiner               1000          10   \n",
       "5   Fuzzy_retail  10  naiveFFIMiner (floating)               1000          10   \n",
       "6   Fuzzy_retail  10                cuFFIMiner               1100          10   \n",
       "7   Fuzzy_retail  10  naiveFFIMiner (floating)               1100          10   \n",
       "8   Fuzzy_retail  10                cuFFIMiner              10000          10   \n",
       "9   Fuzzy_retail  10  naiveFFIMiner (floating)              10000          10   \n",
       "10  Fuzzy_retail  10                  ffiMiner              10000          10   \n",
       "\n",
       "    exec_time  cpu_mem_mb gpu_mem_mb  patterns_found  \n",
       "0      2.5784     2409.14       None        136556.0  \n",
       "1      2.1689     2409.14       None         41169.0  \n",
       "2      2.5631     2409.14       None        114415.0  \n",
       "3      2.1770     2409.14       None         35185.0  \n",
       "4      2.4556     2409.14       None         98151.0  \n",
       "5      2.1097     2432.10       None         30615.0  \n",
       "6      2.2112     2409.14       None         85504.0  \n",
       "7      1.9540     2409.14       None         27117.0  \n",
       "8      1.2986     2409.14       None          3530.0  \n",
       "9      1.1328     2409.14       None          1905.0  \n",
       "10   189.3511     2380.18       None          3530.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv\"\n",
    "retail_sup = [80,90,100,110,1000]\n",
    "\n",
    "print(run_pipeline(retail, sf=1, supports_quant_int=retail_sup, force=False))\n",
    "\n",
    "sf = 10\n",
    "retail_sup = [x * sf for x in retail_sup]\n",
    "run_pipeline(retail, sf=sf, supports_quant_int=retail_sup, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737eea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv (SF=1) ---\n",
      "Supports: [4000, 4500, 5000, 5500, 100000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv (SF=1) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak.csv\n",
      "[prep] Using existing: Fuzzy_kosarak_SF1.csv\n",
      "Processing Fuzzy_kosarak_SF1.csv...\n",
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak_SF1_fixed_10.csv...\n",
      "[convert] method=cudf rows=0 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak_SF1_fixed_10.parquet\n",
      "[convert] method=cudf rows=11041780 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak_SF1.parquet\n",
      "[prep] Dataset 'Fuzzy_kosarak' (SF=1) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=4000 (log exists)\n",
      "[skip] naive (floating) sup=4000 (log exists)\n",
      "[skip] naive (fixed) sup=4000 (log exists)\n",
      "[skip] cuFFI sup=4500 (log exists)\n",
      "[skip] naive (floating) sup=4500 (log exists)\n",
      "[skip] naive (fixed) sup=4500 (log exists)\n",
      "[skip] cuFFI sup=5000 (log exists)\n",
      "[skip] naive (floating) sup=5000 (log exists)\n",
      "[skip] naive (fixed) sup=5000 (log exists)\n",
      "[skip] cuFFI sup=5500 (log exists)\n",
      "[skip] naive (floating) sup=5500 (log exists)\n",
      "[skip] naive (fixed) sup=5500 (log exists)\n",
      "[skip] cuFFI sup=100000 (log exists)\n",
      "[skip] naive (floating) sup=100000 (log exists)\n",
      "[skip] naive (fixed) sup=100000 (log exists)\n",
      "[skip] ffiMiner sup=100000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup4000.out\n",
      "[collect] Parsing naive_floating_sup4000.out\n",
      "[collect] Skipping ffiMiner (sup=4000): log not found.\n",
      "[collect] Parsing cuffi_sup4500.out\n",
      "[collect] Parsing naive_floating_sup4500.out\n",
      "[collect] Skipping ffiMiner (sup=4500): log not found.\n",
      "[collect] Parsing cuffi_sup5000.out\n",
      "[collect] Parsing naive_floating_sup5000.out\n",
      "[collect] Skipping ffiMiner (sup=5000): log not found.\n",
      "[collect] Parsing cuffi_sup5500.out\n",
      "[collect] Parsing naive_floating_sup5500.out\n",
      "[collect] Skipping ffiMiner (sup=5500): log not found.\n",
      "[collect] Parsing cuffi_sup100000.out\n",
      "[collect] Parsing naive_floating_sup100000.out\n",
      "[collect] Parsing ffiminer_sup100000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/metrics_SF1.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_jpg/Fuzzy_kosarak_exec_time_SF1.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_jpg/Fuzzy_kosarak_patterns_found_SF1.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_jpg/legend_SF1.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_pgf/Fuzzy_kosarak_exec_time_SF1.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_pgf/Fuzzy_kosarak_patterns_found_SF1.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_pgf/legend_SF1.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_kosarak (SF=1)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/tables_SF1.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1/figures_SF1.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF1\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_kosarak (SF=1) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv (SF=1) ---\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv (SF=10) ---\n",
      "Supports: [40000, 45000, 50000, 55000, 1000000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv (SF=10) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak.csv\n",
      "[prep] Using existing: Fuzzy_kosarak_SF10.csv\n",
      "Processing Fuzzy_kosarak_SF10.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak_SF10_fixed_10.csv...\n",
      "[convert] method=cudf rows=110417800 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak_SF10_fixed_10.parquet\n",
      "[convert] method=cudf rows=110417800 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak_SF10.parquet\n",
      "[prep] Dataset 'Fuzzy_kosarak' (SF=10) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=40000 (log exists)\n",
      "[skip] naive (floating) sup=40000 (log exists)\n",
      "[skip] naive (fixed) sup=40000 (log exists)\n",
      "[skip] cuFFI sup=45000 (log exists)\n",
      "[skip] naive (floating) sup=45000 (log exists)\n",
      "[skip] naive (fixed) sup=45000 (log exists)\n",
      "[skip] cuFFI sup=50000 (log exists)\n",
      "[skip] naive (floating) sup=50000 (log exists)\n",
      "[skip] naive (fixed) sup=50000 (log exists)\n",
      "[skip] cuFFI sup=55000 (log exists)\n",
      "[skip] naive (floating) sup=55000 (log exists)\n",
      "[skip] naive (fixed) sup=55000 (log exists)\n",
      "[skip] cuFFI sup=1000000 (log exists)\n",
      "[skip] naive (floating) sup=1000000 (log exists)\n",
      "[skip] naive (fixed) sup=1000000 (log exists)\n",
      "[skip] ffiMiner sup=1000000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup40000.out\n",
      "[collect] Parsing naive_floating_sup40000.out\n",
      "[collect] Skipping ffiMiner (sup=40000): log not found.\n",
      "[collect] Parsing cuffi_sup45000.out\n",
      "[collect] Parsing naive_floating_sup45000.out\n",
      "[collect] Skipping ffiMiner (sup=45000): log not found.\n",
      "[collect] Parsing cuffi_sup50000.out\n",
      "[collect] Parsing naive_floating_sup50000.out\n",
      "[collect] Skipping ffiMiner (sup=50000): log not found.\n",
      "[collect] Parsing cuffi_sup55000.out\n",
      "[collect] Parsing naive_floating_sup55000.out\n",
      "[collect] Skipping ffiMiner (sup=55000): log not found.\n",
      "[collect] Parsing cuffi_sup1000000.out\n",
      "[collect] Parsing naive_floating_sup1000000.out\n",
      "[collect] Parsing ffiminer_sup1000000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/metrics_SF10.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_jpg/Fuzzy_kosarak_exec_time_SF10.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_jpg/Fuzzy_kosarak_patterns_found_SF10.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_jpg/legend_SF10.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_pgf/Fuzzy_kosarak_exec_time_SF10.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_pgf/Fuzzy_kosarak_patterns_found_SF10.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_pgf/legend_SF10.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_kosarak (SF=10)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/tables_SF10.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10/figures_SF10.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_kosarak/SF10\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_kosarak (SF=10) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv (SF=10) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sf</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_mb</th>\n",
       "      <th>patterns_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>40000</td>\n",
       "      <td>10</td>\n",
       "      <td>13.2102</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>175185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>40000</td>\n",
       "      <td>10</td>\n",
       "      <td>8.6202</td>\n",
       "      <td>14289.19</td>\n",
       "      <td>None</td>\n",
       "      <td>44885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>45000</td>\n",
       "      <td>10</td>\n",
       "      <td>10.6116</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>97848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>45000</td>\n",
       "      <td>10</td>\n",
       "      <td>8.7254</td>\n",
       "      <td>14817.03</td>\n",
       "      <td>None</td>\n",
       "      <td>28590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>8.5808</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>64760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>50000</td>\n",
       "      <td>10</td>\n",
       "      <td>7.7058</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>20393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>55000</td>\n",
       "      <td>10</td>\n",
       "      <td>7.4040</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>47495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>55000</td>\n",
       "      <td>10</td>\n",
       "      <td>7.6230</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>15718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.5531</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.2766</td>\n",
       "      <td>14088.52</td>\n",
       "      <td>None</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fuzzy_kosarak</td>\n",
       "      <td>10</td>\n",
       "      <td>ffiMiner</td>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>340.6111</td>\n",
       "      <td>18979.44</td>\n",
       "      <td>None</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  sf                 algorithm  support_quant_int  \\\n",
       "0   Fuzzy_kosarak  10                cuFFIMiner              40000   \n",
       "1   Fuzzy_kosarak  10  naiveFFIMiner (floating)              40000   \n",
       "2   Fuzzy_kosarak  10                cuFFIMiner              45000   \n",
       "3   Fuzzy_kosarak  10  naiveFFIMiner (floating)              45000   \n",
       "4   Fuzzy_kosarak  10                cuFFIMiner              50000   \n",
       "5   Fuzzy_kosarak  10  naiveFFIMiner (floating)              50000   \n",
       "6   Fuzzy_kosarak  10                cuFFIMiner              55000   \n",
       "7   Fuzzy_kosarak  10  naiveFFIMiner (floating)              55000   \n",
       "8   Fuzzy_kosarak  10                cuFFIMiner            1000000   \n",
       "9   Fuzzy_kosarak  10  naiveFFIMiner (floating)            1000000   \n",
       "10  Fuzzy_kosarak  10                  ffiMiner            1000000   \n",
       "\n",
       "    quant_mult  exec_time  cpu_mem_mb gpu_mem_mb  patterns_found  \n",
       "0           10    13.2102    14088.52       None        175185.0  \n",
       "1           10     8.6202    14289.19       None         44885.0  \n",
       "2           10    10.6116    14088.52       None         97848.0  \n",
       "3           10     8.7254    14817.03       None         28590.0  \n",
       "4           10     8.5808    14088.52       None         64760.0  \n",
       "5           10     7.7058    14088.52       None         20393.0  \n",
       "6           10     7.4040    14088.52       None         47495.0  \n",
       "7           10     7.6230    14088.52       None         15718.0  \n",
       "8           10     1.5531    14088.52       None           191.0  \n",
       "9           10     4.2766    14088.52       None           105.0  \n",
       "10          10   340.6111    18979.44       None           191.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosarak = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv\"\n",
    "kosarak_sup = [4000,4500,5000,5500,100000]\n",
    "\n",
    "run_pipeline(kosarak, sf=1, supports_quant_int=kosarak_sup, force=False)\n",
    "\n",
    "sf = 10\n",
    "kosarak_sup = [x * sf for x in kosarak_sup]\n",
    "run_pipeline(kosarak, sf=sf, supports_quant_int=kosarak_sup, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb3f1e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv (SF=1) ---\n",
      "Supports: [100000, 110000, 120000, 130000, 280000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv (SF=1) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb.csv\n",
      "[prep] Using existing: Fuzzy_pumsb_SF1.csv\n",
      "Processing Fuzzy_pumsb_SF1.csv...\n",
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb_SF1_fixed_10.csv...\n",
      "[convert] method=cudf rows=4913349 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb_SF1_fixed_10.parquet\n",
      "[convert] method=cudf rows=4913349 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb_SF1.parquet\n",
      "[prep] Dataset 'Fuzzy_pumsb' (SF=1) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=100000 (log exists)\n",
      "[skip] naive (floating) sup=100000 (log exists)\n",
      "[skip] naive (fixed) sup=100000 (log exists)\n",
      "[skip] cuFFI sup=110000 (log exists)\n",
      "[skip] naive (floating) sup=110000 (log exists)\n",
      "[skip] naive (fixed) sup=110000 (log exists)\n",
      "[skip] cuFFI sup=120000 (log exists)\n",
      "[skip] naive (floating) sup=120000 (log exists)\n",
      "[skip] naive (fixed) sup=120000 (log exists)\n",
      "[skip] cuFFI sup=130000 (log exists)\n",
      "[skip] naive (floating) sup=130000 (log exists)\n",
      "[skip] naive (fixed) sup=130000 (log exists)\n",
      "[skip] cuFFI sup=280000 (log exists)\n",
      "[skip] naive (floating) sup=280000 (log exists)\n",
      "[skip] naive (fixed) sup=280000 (log exists)\n",
      "[skip] ffiMiner sup=280000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup100000.out\n",
      "[collect] Parsing naive_floating_sup100000.out\n",
      "[collect] Skipping ffiMiner (sup=100000): log not found.\n",
      "[collect] Parsing cuffi_sup110000.out\n",
      "[collect] Parsing naive_floating_sup110000.out\n",
      "[collect] Skipping ffiMiner (sup=110000): log not found.\n",
      "[collect] Parsing cuffi_sup120000.out\n",
      "[collect] Parsing naive_floating_sup120000.out\n",
      "[collect] Skipping ffiMiner (sup=120000): log not found.\n",
      "[collect] Parsing cuffi_sup130000.out\n",
      "[collect] Parsing naive_floating_sup130000.out\n",
      "[collect] Skipping ffiMiner (sup=130000): log not found.\n",
      "[collect] Parsing cuffi_sup280000.out\n",
      "[collect] Parsing naive_floating_sup280000.out\n",
      "[collect] Parsing ffiminer_sup280000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/metrics_SF1.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_jpg/Fuzzy_pumsb_exec_time_SF1.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_jpg/Fuzzy_pumsb_patterns_found_SF1.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_jpg/legend_SF1.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_pgf/Fuzzy_pumsb_exec_time_SF1.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_pgf/Fuzzy_pumsb_patterns_found_SF1.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_pgf/legend_SF1.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_pumsb (SF=1)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/tables_SF1.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1/figures_SF1.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF1\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_pumsb (SF=1) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv (SF=1) ---\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv (SF=10) ---\n",
      "Supports: [1000000, 1100000, 1200000, 1300000, 2800000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv (SF=10) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb.csv\n",
      "[prep] Using existing: Fuzzy_pumsb_SF10.csv\n",
      "Processing Fuzzy_pumsb_SF10.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb_SF10_fixed_10.csv...\n",
      "[convert] method=cudf rows=49133490 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb_SF10_fixed_10.parquet\n",
      "[convert] method=cudf rows=49133490 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb_SF10.parquet\n",
      "[prep] Dataset 'Fuzzy_pumsb' (SF=10) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=1000000 (log exists)\n",
      "[skip] naive (floating) sup=1000000 (log exists)\n",
      "[skip] naive (fixed) sup=1000000 (log exists)\n",
      "[skip] cuFFI sup=1100000 (log exists)\n",
      "[skip] naive (floating) sup=1100000 (log exists)\n",
      "[skip] naive (fixed) sup=1100000 (log exists)\n",
      "[skip] cuFFI sup=1200000 (log exists)\n",
      "[skip] naive (floating) sup=1200000 (log exists)\n",
      "[skip] naive (fixed) sup=1200000 (log exists)\n",
      "[skip] cuFFI sup=1300000 (log exists)\n",
      "[skip] naive (floating) sup=1300000 (log exists)\n",
      "[skip] naive (fixed) sup=1300000 (log exists)\n",
      "[skip] cuFFI sup=2800000 (log exists)\n",
      "[skip] naive (floating) sup=2800000 (log exists)\n",
      "[skip] naive (fixed) sup=2800000 (log exists)\n",
      "[skip] ffiMiner sup=2800000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup1000000.out\n",
      "[collect] Parsing naive_floating_sup1000000.out\n",
      "[collect] Skipping ffiMiner (sup=1000000): log not found.\n",
      "[collect] Parsing cuffi_sup1100000.out\n",
      "[collect] Parsing naive_floating_sup1100000.out\n",
      "[collect] Skipping ffiMiner (sup=1100000): log not found.\n",
      "[collect] Parsing cuffi_sup1200000.out\n",
      "[collect] Parsing naive_floating_sup1200000.out\n",
      "[collect] Skipping ffiMiner (sup=1200000): log not found.\n",
      "[collect] Parsing cuffi_sup1300000.out\n",
      "[collect] Parsing naive_floating_sup1300000.out\n",
      "[collect] Skipping ffiMiner (sup=1300000): log not found.\n",
      "[collect] Parsing cuffi_sup2800000.out\n",
      "[collect] Parsing naive_floating_sup2800000.out\n",
      "[collect] Parsing ffiminer_sup2800000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/metrics_SF10.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_jpg/Fuzzy_pumsb_exec_time_SF10.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_jpg/Fuzzy_pumsb_patterns_found_SF10.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_jpg/legend_SF10.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_pgf/Fuzzy_pumsb_exec_time_SF10.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_pgf/Fuzzy_pumsb_patterns_found_SF10.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_pgf/legend_SF10.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_pumsb (SF=10)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/tables_SF10.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10/figures_SF10.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/SF10\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_pumsb (SF=10) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv (SF=10) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sf</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_mb</th>\n",
       "      <th>patterns_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>100.7956</td>\n",
       "      <td>5672.14</td>\n",
       "      <td>None</td>\n",
       "      <td>283443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>14.7923</td>\n",
       "      <td>6109.31</td>\n",
       "      <td>None</td>\n",
       "      <td>40214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1100000</td>\n",
       "      <td>10</td>\n",
       "      <td>55.8643</td>\n",
       "      <td>5672.14</td>\n",
       "      <td>None</td>\n",
       "      <td>159707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1100000</td>\n",
       "      <td>10</td>\n",
       "      <td>9.4286</td>\n",
       "      <td>6090.95</td>\n",
       "      <td>None</td>\n",
       "      <td>24829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1200000</td>\n",
       "      <td>10</td>\n",
       "      <td>32.6661</td>\n",
       "      <td>5672.14</td>\n",
       "      <td>None</td>\n",
       "      <td>94084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1200000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.6761</td>\n",
       "      <td>6077.79</td>\n",
       "      <td>None</td>\n",
       "      <td>15721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>1300000</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0710</td>\n",
       "      <td>5672.14</td>\n",
       "      <td>None</td>\n",
       "      <td>57209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>1300000</td>\n",
       "      <td>10</td>\n",
       "      <td>5.1354</td>\n",
       "      <td>6058.49</td>\n",
       "      <td>None</td>\n",
       "      <td>10208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>2800000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.3068</td>\n",
       "      <td>5672.14</td>\n",
       "      <td>None</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>2800000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8480</td>\n",
       "      <td>5715.30</td>\n",
       "      <td>None</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fuzzy_pumsb</td>\n",
       "      <td>10</td>\n",
       "      <td>ffiMiner</td>\n",
       "      <td>2800000</td>\n",
       "      <td>10</td>\n",
       "      <td>187.2361</td>\n",
       "      <td>10926.56</td>\n",
       "      <td>None</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset  sf                 algorithm  support_quant_int  quant_mult  \\\n",
       "0   Fuzzy_pumsb  10                cuFFIMiner            1000000          10   \n",
       "1   Fuzzy_pumsb  10  naiveFFIMiner (floating)            1000000          10   \n",
       "2   Fuzzy_pumsb  10                cuFFIMiner            1100000          10   \n",
       "3   Fuzzy_pumsb  10  naiveFFIMiner (floating)            1100000          10   \n",
       "4   Fuzzy_pumsb  10                cuFFIMiner            1200000          10   \n",
       "5   Fuzzy_pumsb  10  naiveFFIMiner (floating)            1200000          10   \n",
       "6   Fuzzy_pumsb  10                cuFFIMiner            1300000          10   \n",
       "7   Fuzzy_pumsb  10  naiveFFIMiner (floating)            1300000          10   \n",
       "8   Fuzzy_pumsb  10                cuFFIMiner            2800000          10   \n",
       "9   Fuzzy_pumsb  10  naiveFFIMiner (floating)            2800000          10   \n",
       "10  Fuzzy_pumsb  10                  ffiMiner            2800000          10   \n",
       "\n",
       "    exec_time  cpu_mem_mb gpu_mem_mb  patterns_found  \n",
       "0    100.7956     5672.14       None        283443.0  \n",
       "1     14.7923     6109.31       None         40214.0  \n",
       "2     55.8643     5672.14       None        159707.0  \n",
       "3      9.4286     6090.95       None         24829.0  \n",
       "4     32.6661     5672.14       None         94084.0  \n",
       "5      6.6761     6077.79       None         15721.0  \n",
       "6     20.0710     5672.14       None         57209.0  \n",
       "7      5.1354     6058.49       None         10208.0  \n",
       "8      1.3068     5672.14       None           282.0  \n",
       "9      1.8480     5715.30       None            99.0  \n",
       "10   187.2361    10926.56       None           282.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pumsb = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv\"\n",
    "pumsb_sup = [100000,110000,120000,130000,280000]\n",
    "\n",
    "run_pipeline(pumsb, sf=1, supports_quant_int=pumsb_sup, force=False)\n",
    "\n",
    "sf = 10\n",
    "pumsb_sup = [x * sf for x in pumsb_sup]\n",
    "run_pipeline(pumsb, sf=sf, supports_quant_int=pumsb_sup, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab04144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv (SF=1) ---\n",
      "Supports: [3000, 3500, 4000, 4500, 5000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv (SF=1) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K.csv\n",
      "[prep] Using existing: Fuzzy_T10I4D100K_SF1.csv\n",
      "Processing Fuzzy_T10I4D100K_SF1.csv...\n",
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K_SF1_fixed_10.csv...\n",
      "[convert] method=cudf rows=1091692 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K_SF1_fixed_10.parquet\n",
      "[convert] method=cudf rows=1091692 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K_SF1.parquet\n",
      "[prep] Dataset 'Fuzzy_T10I4D100K' (SF=1) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=3000 (log exists)\n",
      "[skip] naive (floating) sup=3000 (log exists)\n",
      "[skip] naive (fixed) sup=3000 (log exists)\n",
      "[skip] cuFFI sup=3500 (log exists)\n",
      "[skip] naive (floating) sup=3500 (log exists)\n",
      "[skip] naive (fixed) sup=3500 (log exists)\n",
      "[skip] cuFFI sup=4000 (log exists)\n",
      "[skip] naive (floating) sup=4000 (log exists)\n",
      "[skip] naive (fixed) sup=4000 (log exists)\n",
      "[skip] cuFFI sup=4500 (log exists)\n",
      "[skip] naive (floating) sup=4500 (log exists)\n",
      "[skip] naive (fixed) sup=4500 (log exists)\n",
      "[skip] cuFFI sup=5000 (log exists)\n",
      "[skip] naive (floating) sup=5000 (log exists)\n",
      "[skip] naive (fixed) sup=5000 (log exists)\n",
      "[skip] ffiMiner sup=5000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup3000.out\n",
      "[collect] Parsing naive_floating_sup3000.out\n",
      "[collect] Skipping ffiMiner (sup=3000): log not found.\n",
      "[collect] Parsing cuffi_sup3500.out\n",
      "[collect] Parsing naive_floating_sup3500.out\n",
      "[collect] Skipping ffiMiner (sup=3500): log not found.\n",
      "[collect] Parsing cuffi_sup4000.out\n",
      "[collect] Parsing naive_floating_sup4000.out\n",
      "[collect] Skipping ffiMiner (sup=4000): log not found.\n",
      "[collect] Parsing cuffi_sup4500.out\n",
      "[collect] Parsing naive_floating_sup4500.out\n",
      "[collect] Skipping ffiMiner (sup=4500): log not found.\n",
      "[collect] Parsing cuffi_sup5000.out\n",
      "[collect] Parsing naive_floating_sup5000.out\n",
      "[collect] Parsing ffiminer_sup5000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/metrics_SF1.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_jpg/Fuzzy_T10I4D100K_exec_time_SF1.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_jpg/Fuzzy_T10I4D100K_patterns_found_SF1.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_jpg/legend_SF1.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_pgf/Fuzzy_T10I4D100K_exec_time_SF1.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_pgf/Fuzzy_T10I4D100K_patterns_found_SF1.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_pgf/legend_SF1.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_T10I4D100K (SF=1)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/tables_SF1.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1/figures_SF1.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF1\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_T10I4D100K (SF=1) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv (SF=1) ---\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv (SF=100) ---\n",
      "Supports: [300000, 350000, 400000, 450000, 500000]\n",
      "--- üöÄ Starting Pipeline for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv (SF=100) ---\n",
      "--- 1. Preparing Dataset ---\n",
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K.csv\n",
      "[prep] Using existing: Fuzzy_T10I4D100K_SF100.csv\n",
      "Processing Fuzzy_T10I4D100K_SF100.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor determined: 10 (10^1)\n",
      "Writing fixed point file to /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K_SF100_fixed_10.csv...\n",
      "[convert] method=cudf rows=109169200 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K_SF100_fixed_10.parquet\n",
      "[convert] method=cudf rows=109169200 file=/export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_T10I4D100K/Fuzzy_T10I4D100K_SF100.parquet\n",
      "[prep] Dataset 'Fuzzy_T10I4D100K' (SF=100) prepared.\n",
      "--- 2. Running Experiments ---\n",
      "[skip] cuFFI sup=300000 (log exists)\n",
      "[skip] naive (floating) sup=300000 (log exists)\n",
      "[skip] naive (fixed) sup=300000 (log exists)\n",
      "[skip] cuFFI sup=350000 (log exists)\n",
      "[skip] naive (floating) sup=350000 (log exists)\n",
      "[skip] naive (fixed) sup=350000 (log exists)\n",
      "[skip] cuFFI sup=400000 (log exists)\n",
      "[skip] naive (floating) sup=400000 (log exists)\n",
      "[skip] naive (fixed) sup=400000 (log exists)\n",
      "[skip] cuFFI sup=450000 (log exists)\n",
      "[skip] naive (floating) sup=450000 (log exists)\n",
      "[skip] naive (fixed) sup=450000 (log exists)\n",
      "[skip] cuFFI sup=500000 (log exists)\n",
      "[skip] naive (floating) sup=500000 (log exists)\n",
      "[skip] naive (fixed) sup=500000 (log exists)\n",
      "[skip] ffiMiner sup=500000 (log exists)\n",
      "[run] All experiments complete.\n",
      "--- 3. Collecting Results ---\n",
      "[collect] Parsing cuffi_sup300000.out\n",
      "[collect] Parsing naive_floating_sup300000.out\n",
      "[collect] Skipping ffiMiner (sup=300000): log not found.\n",
      "[collect] Parsing cuffi_sup350000.out\n",
      "[collect] Parsing naive_floating_sup350000.out\n",
      "[collect] Skipping ffiMiner (sup=350000): log not found.\n",
      "[collect] Parsing cuffi_sup400000.out\n",
      "[collect] Parsing naive_floating_sup400000.out\n",
      "[collect] Skipping ffiMiner (sup=400000): log not found.\n",
      "[collect] Parsing cuffi_sup450000.out\n",
      "[collect] Parsing naive_floating_sup450000.out\n",
      "[collect] Skipping ffiMiner (sup=450000): log not found.\n",
      "[collect] Parsing cuffi_sup500000.out\n",
      "[collect] Parsing naive_floating_sup500000.out\n",
      "[collect] Parsing ffiminer_sup500000.out\n",
      "[collect] Metrics saved to /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/metrics_SF100.csv\n",
      "--- 4. Generating JPG Plots (using Matplotlib) ---\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_jpg/Fuzzy_T10I4D100K_exec_time_SF100.jpg\n",
      "[plot] wrote JPG: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_jpg/Fuzzy_T10I4D100K_patterns_found_SF100.jpg\n",
      "[plot] wrote JPG legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_jpg/legend_SF100.jpg\n",
      "[plot] JPG plot generation done.\n",
      "--- 5. Generating PGF Plots (using Matplotlib) ---\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_pgf/Fuzzy_T10I4D100K_exec_time_SF100.pgf\n",
      "[plot] wrote PGF: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_pgf/Fuzzy_T10I4D100K_patterns_found_SF100.pgf\n",
      "[plot] wrote PGF legend: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_pgf/legend_SF100.pgf\n",
      "[plot] PGF plot generation done.\n",
      "--- 6. Generating LaTeX Outputs ---\n",
      "[latex] Generating all LaTeX outputs for Fuzzy_T10I4D100K (SF=100)...\n",
      "[latex] Generated LaTeX table: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/tables_SF100.tex\n",
      "[latex] Generated LaTeX figures wrapper: /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100/figures_SF100.tex\n",
      "[latex] All LaTeX outputs generated in /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_T10I4D100K/SF100\n",
      "--- ‚úÖ Pipeline Complete for Fuzzy_T10I4D100K (SF=100) ---\n",
      "--- ‚úÖ Pipeline Complete for https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv (SF=100) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2424910/789897141.py:569: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_time = df_time.applymap(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"---\")\n",
      "/tmp/ipykernel_2424910/789897141.py:574: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_patterns = df_patterns.applymap(lambda x: f\"{x:,.0f}\" if pd.notna(x) else \"---\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sf</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_mb</th>\n",
       "      <th>patterns_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>300000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.2295</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>2325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>300000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.1500</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>2045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>350000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.2593</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>350000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0322</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>1407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>400000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.1924</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>1154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>400000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.1527</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>1069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>450000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0946</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>450000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.3009</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>500000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.2103</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner (floating)</td>\n",
       "      <td>500000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0697</td>\n",
       "      <td>14640.06</td>\n",
       "      <td>None</td>\n",
       "      <td>733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fuzzy_T10I4D100K</td>\n",
       "      <td>100</td>\n",
       "      <td>ffiMiner</td>\n",
       "      <td>500000</td>\n",
       "      <td>10</td>\n",
       "      <td>1973.5758</td>\n",
       "      <td>17458.71</td>\n",
       "      <td>None</td>\n",
       "      <td>787.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset   sf                 algorithm  support_quant_int  \\\n",
       "0   Fuzzy_T10I4D100K  100                cuFFIMiner             300000   \n",
       "1   Fuzzy_T10I4D100K  100  naiveFFIMiner (floating)             300000   \n",
       "2   Fuzzy_T10I4D100K  100                cuFFIMiner             350000   \n",
       "3   Fuzzy_T10I4D100K  100  naiveFFIMiner (floating)             350000   \n",
       "4   Fuzzy_T10I4D100K  100                cuFFIMiner             400000   \n",
       "5   Fuzzy_T10I4D100K  100  naiveFFIMiner (floating)             400000   \n",
       "6   Fuzzy_T10I4D100K  100                cuFFIMiner             450000   \n",
       "7   Fuzzy_T10I4D100K  100  naiveFFIMiner (floating)             450000   \n",
       "8   Fuzzy_T10I4D100K  100                cuFFIMiner             500000   \n",
       "9   Fuzzy_T10I4D100K  100  naiveFFIMiner (floating)             500000   \n",
       "10  Fuzzy_T10I4D100K  100                  ffiMiner             500000   \n",
       "\n",
       "    quant_mult  exec_time  cpu_mem_mb gpu_mem_mb  patterns_found  \n",
       "0           10     2.2295    14640.06       None          2325.0  \n",
       "1           10     6.1500    14640.06       None          2045.0  \n",
       "2           10     2.2593    14640.06       None          1557.0  \n",
       "3           10     6.0322    14640.06       None          1407.0  \n",
       "4           10     2.1924    14640.06       None          1154.0  \n",
       "5           10     6.1527    14640.06       None          1069.0  \n",
       "6           10     2.0946    14640.06       None           922.0  \n",
       "7           10     6.3009    14640.06       None           866.0  \n",
       "8           10     2.2103    14640.06       None           787.0  \n",
       "9           10     6.0697    14640.06       None           733.0  \n",
       "10          10  1973.5758    17458.71       None           787.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t10 = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv\"\n",
    "t10_sup = [3000,3500,4000,4500,5000]\n",
    "\n",
    "run_pipeline(t10, sf=1, supports_quant_int=t10_sup, force=False)\n",
    "\n",
    "sf = 100\n",
    "\n",
    "t10_sup = [x * sf for x in t10_sup]\n",
    "run_pipeline(t10, sf=sf, supports_quant_int=t10_sup, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577f75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67731222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1b867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
