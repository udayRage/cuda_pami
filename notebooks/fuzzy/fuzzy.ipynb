{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111744c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ultra-clean A/B pipeline: prep -> run (subprocess) -> collect -> plot\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, sys, re, json, time, subprocess, textwrap\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# Project paths\n",
    "# -----------------------\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent  # adjust if needed\n",
    "DATA_DIR     = PROJECT_ROOT / \"data\" / \"fuzzy\"\n",
    "RESULTS_DIR  = PROJECT_ROOT / \"results\" / \"fuzzy\"\n",
    "for p in (DATA_DIR, RESULTS_DIR): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Step 1: Prep (URL + SF)\n",
    "# -----------------------\n",
    "def _filename_from_url(url: str) -> str:\n",
    "    return Path(url.split(\"?\")[0]).name\n",
    "\n",
    "def _download(url: str, base_dir: Path) -> Path:\n",
    "    filename = _filename_from_url(url)\n",
    "    name_root = Path(filename).stem\n",
    "    dst_dir = base_dir / name_root\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out = dst_dir / filename\n",
    "    if out.exists():\n",
    "        print(f\"[download] Using cached: {out}\")\n",
    "        return out\n",
    "    legacy = base_dir / filename\n",
    "    if legacy.exists():\n",
    "        out.write_bytes(legacy.read_bytes())\n",
    "        print(f\"[download] Moved legacy file -> {out}\")\n",
    "        return out\n",
    "    print(f\"[download] Fetch {url}\")\n",
    "    r = requests.get(url, timeout=60); r.raise_for_status()\n",
    "    out.write_bytes(r.content)\n",
    "    print(f\"[download] Saved {out}\")\n",
    "    return out\n",
    "\n",
    "def prepare_dataset(url: str, sf: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        'dataset_name', 'original',\n",
    "        'floating_text', 'floating_parquet',\n",
    "        'fixed_parquet', 'quant_mult'\n",
    "      }\n",
    "    Uses your repo scripts:\n",
    "      - scripts.replicate_file.replicate_file\n",
    "      - scripts.fixedpoint_normalize.normalize_file\n",
    "    \"\"\"\n",
    "    if str(PROJECT_ROOT) not in sys.path:\n",
    "        sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "    original = _download(url, DATA_DIR)\n",
    "    dataset_name = original.parent.name\n",
    "\n",
    "    # 1) replicate floating text (SF-concatenated)\n",
    "    from scripts.fuzzy.replicate_file import replicate_file\n",
    "    sf = max(1, int(sf))\n",
    "    floating_text = original.with_name(f\"{original.stem}_SF{sf}_floating{original.suffix}\")\n",
    "    if floating_text.exists():\n",
    "        print(f\"[prep] Using existing: {floating_text.name}\")\n",
    "    else:\n",
    "        replicate_file(str(original), sf, str(floating_text))\n",
    "        print(f\"[prep] Made: {floating_text.name}\")\n",
    "\n",
    "    # 2) make fixed parquet + quant_mult AND floating parquet\n",
    "    from scripts.fuzzy.fixedpoint_normalize import normalize_file\n",
    "    stem = floating_text.stem.replace(\"_floating\", \"\")\n",
    "    fixed_parquet    = floating_text.with_name(f\"{stem}_fixed.parquet\")\n",
    "    quant_file       = floating_text.with_name(f\"{stem}_quant_mult.txt\")\n",
    "    floating_parquet = floating_text.with_suffix(\".parquet\")\n",
    "\n",
    "    if not fixed_parquet.exists() or not quant_file.exists() or not floating_parquet.exists():\n",
    "        print(\"[prep] Running normalize_file to get parquet(s) & quant_mult …\")\n",
    "        _ = normalize_file(str(floating_text), write_fixed_text=False)\n",
    "\n",
    "    if not fixed_parquet.exists():    raise FileNotFoundError(f\"Missing: {fixed_parquet}\")\n",
    "    if not floating_parquet.exists(): raise FileNotFoundError(f\"Missing: {floating_parquet}\")\n",
    "    if not quant_file.exists():       raise FileNotFoundError(f\"Missing: {quant_file}\")\n",
    "\n",
    "    quant_mult = int(quant_file.read_text().strip())\n",
    "    return {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"original\": str(original),\n",
    "        \"floating_text\": str(floating_text),\n",
    "        \"floating_parquet\": str(floating_parquet),\n",
    "        \"fixed_parquet\": str(fixed_parquet),\n",
    "        \"quant_mult\": quant_mult,\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Step 2: Run miners in separate processes (clean)\n",
    "# -------------------------------------------------\n",
    "def _run_subprocess(args: List[str], log_path: Path, err_path: Path, cwd: Path, extra_env: Optional[Dict[str, str]]=None) -> int:\n",
    "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    err_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    env = os.environ.copy()\n",
    "    env[\"PYTHONPATH\"] = str(PROJECT_ROOT) + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "    if extra_env:\n",
    "        env.update({k: str(v) for k, v in extra_env.items()})\n",
    "    print(\"[run] \", \" \".join(args))\n",
    "    with open(log_path, \"w\") as out, open(err_path, \"w\") as err:\n",
    "        proc = subprocess.run(args, cwd=cwd, env=env, stdout=out, stderr=err, text=True)\n",
    "    print(f\"[run] exit={proc.returncode}  log={log_path}  err={err_path}\")\n",
    "    return proc.returncode\n",
    "\n",
    "def run_cuffi_cli(\n",
    "    fixed_parquet: str,\n",
    "    quant_mult: int,\n",
    "    sup_int: int,\n",
    "    out_dir: Path,\n",
    "    allocator=\"rmm_managed\",\n",
    "    gds=\"off\",\n",
    "    pinned=True,\n",
    "    managed_prefetch=True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    cuFFIMiner expects pre-scaled parquet (item, prob:uint32, txn_id).\n",
    "    NOTE (your toggle): gds='off' => force cuFile => GDS ON. gds='on' => POSIX => GDS OFF.\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logs_dir = out_dir / \"logs\"\n",
    "    patterns_path = out_dir / f\"patterns_cuffi_{allocator}_{gds}_{'pin' if pinned else 'nopin'}_sup{sup_int}.txt\"\n",
    "    log_path      = logs_dir / f\"cuffi_sup{sup_int}.out\"\n",
    "    err_path      = logs_dir / f\"cuffi_sup{sup_int}.err\"\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"src.algorithms.fuzzy.cuFFIMiner\",\n",
    "        str(fixed_parquet),\n",
    "        str(int(sup_int)),\n",
    "        str(int(quant_mult)),\n",
    "        \"-o\", str(patterns_path),\n",
    "        \"--allocator\", allocator,\n",
    "        \"--gds\", gds,\n",
    "    ]\n",
    "    if pinned:           cmd.append(\"--pinned\")\n",
    "    if managed_prefetch: cmd.append(\"--managed-prefetch\")\n",
    "\n",
    "    rc = _run_subprocess(cmd, log_path, err_path, cwd=PROJECT_ROOT)\n",
    "    return {\"rc\": rc, \"patterns\": str(patterns_path), \"stdout\": str(log_path), \"stderr\": str(err_path)}\n",
    "\n",
    "def run_naive_cli(\n",
    "    floating_text_or_parquet: str,\n",
    "    quant_mult: int,\n",
    "    sup_int: int,\n",
    "    out_dir: Path\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    naiveFFIMiner expects float min_support (we convert from quantized int).\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logs_dir = out_dir / \"logs\"\n",
    "    sup_float = sup_int / max(1, int(quant_mult))\n",
    "    patterns_path = out_dir / f\"patterns_naive_sup{sup_int}.txt\"\n",
    "    log_path      = logs_dir / f\"naive_sup{sup_int}.out\"\n",
    "    err_path      = logs_dir / f\"naive_sup{sup_int}.err\"\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"src.algorithms.fuzzy.naiveFFIMiner\",\n",
    "        str(floating_text_or_parquet),\n",
    "        f\"{sup_float:.12g}\",\n",
    "        \"-o\", str(patterns_path),\n",
    "    ]\n",
    "    rc = _run_subprocess(cmd, log_path, err_path, cwd=PROJECT_ROOT)\n",
    "    return {\"rc\": rc, \"patterns\": str(patterns_path), \"stdout\": str(log_path), \"stderr\": str(err_path)}\n",
    "\n",
    "# ---------------------------------------\n",
    "# Step 3: Parse logs -> metrics -> plots\n",
    "# ---------------------------------------\n",
    "_METRIC_PATTERNS = {\n",
    "    \"exec_time\":          re.compile(r\"Execution Time:\\s*([0-9.]+)\\s*seconds\", re.I),\n",
    "    \"cpu_mem_mb\":         re.compile(r\"Peak CPU Memory Usage:\\s*([0-9.]+)\\s*MB\", re.I),\n",
    "    \"gpu_mem_mb\":         re.compile(r\"Peak GPU \\(driver\\) Used:\\s*([0-9.]+)\\s*MB\", re.I),\n",
    "    \"pool_used_mb\":       re.compile(r\"Peak Pool Used:\\s*([0-9.]+)\\s*MB\", re.I),\n",
    "    \"pool_total_mb\":      re.compile(r\"Peak Pool Total:\\s*([0-9.]+)\\s*MB\", re.I),\n",
    "    \"rmm_peak_mb\":        re.compile(r\"RMM Statistics Peak:\\s*([0-9.]+)\\s*MB\", re.I),\n",
    "    \"patterns_found\":     re.compile(r\"Patterns Found:\\s*([0-9]+)\", re.I),\n",
    "    # NEW: theory metrics printed by miners’ print_results()\n",
    "    \"theory_static_mb\":   re.compile(r\"Theoretical Static:\\s*([0-9.,]+)\\s*MB\", re.I),\n",
    "    \"theory_peak_mb\":     re.compile(r\"Theoretical Peak:\\s*([0-9.,]+)\\s*MB\", re.I),\n",
    "}\n",
    "\n",
    "def _parse_first_float_mb(text: str, rgx: re.Pattern) -> Optional[float]:\n",
    "    m = rgx.search(text)\n",
    "    if not m:\n",
    "        return None\n",
    "    # accept 1,234.56 formats\n",
    "    return float(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "def parse_metrics_from_log(log_path: Path) -> Dict[str, Optional[float]]:\n",
    "    text = Path(log_path).read_text(errors=\"ignore\")\n",
    "    out: Dict[str, Optional[float]] = {}\n",
    "    for k, rgx in _METRIC_PATTERNS.items():\n",
    "        if k in (\"theory_static_mb\", \"theory_peak_mb\"):\n",
    "            out[k] = _parse_first_float_mb(text, rgx)\n",
    "        else:\n",
    "            m = rgx.search(text)\n",
    "            out[k] = float(m.group(1)) if m else None\n",
    "    return out\n",
    "\n",
    "def collect_results(dataset_name: str, sf: int, quant_mult: int, supports: List[int], ds_dir: Path) -> pd.DataFrame:\n",
    "    logs_dir = ds_dir / \"logs\"\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for sup in supports:\n",
    "        cuffi_log = logs_dir / f\"cuffi_sup{sup}.out\"\n",
    "        naive_log = logs_dir / f\"naive_sup{sup}.out\"\n",
    "\n",
    "        # Backward-compat fallback if previous runs stored logs in ds_dir root\n",
    "        if not cuffi_log.exists():\n",
    "            alt = ds_dir / f\"cuffi_sup{sup}.out\"\n",
    "            if alt.exists(): cuffi_log = alt\n",
    "        if not naive_log.exists():\n",
    "            alt = ds_dir / f\"naive_sup{sup}.out\"\n",
    "            if alt.exists(): naive_log = alt\n",
    "\n",
    "        if cuffi_log.exists():\n",
    "            m = parse_metrics_from_log(cuffi_log)\n",
    "            rows.append({\n",
    "                \"dataset\": dataset_name, \"sf\": sf, \"algorithm\": \"cuFFIMiner\",\n",
    "                \"support_quant_int\": sup, \"quant_mult\": quant_mult,\n",
    "                **m\n",
    "            })\n",
    "        if naive_log.exists():\n",
    "            m = parse_metrics_from_log(naive_log)\n",
    "            rows.append({\n",
    "                \"dataset\": dataset_name, \"sf\": sf, \"algorithm\": \"naiveFFIMiner\",\n",
    "                \"support_quant_int\": sup, \"quant_mult\": quant_mult,\n",
    "                **m\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Optional convenience bytes\n",
    "    if \"theory_peak_mb\" in df.columns and df[\"theory_peak_mb\"].notna().any():\n",
    "        df[\"theory_peak_bytes\"] = df[\"theory_peak_mb\"] * (1024**2)\n",
    "    if \"gpu_mem_mb\" in df.columns and df[\"gpu_mem_mb\"].notna().any():\n",
    "        df[\"gpu_mem_bytes\"] = df[\"gpu_mem_mb\"] * (1024**2)\n",
    "    return df\n",
    "\n",
    "# ---- plotting (PDF, LaTeX-friendly) ----\n",
    "plt.rcParams.update({\n",
    "    \"pdf.fonttype\": 42, \"ps.fonttype\": 42, \"figure.dpi\": 150,\n",
    "    \"font.size\": 11, \"axes.titlesize\": 12, \"axes.labelsize\": 11, \"legend.fontsize\": 9,\n",
    "})\n",
    "\n",
    "_LABELS = {\n",
    "    \"exec_time\": \"Execution Time (s)\",\n",
    "    \"cpu_mem_mb\": \"Peak CPU Memory (MB)\",\n",
    "    \"gpu_mem_mb\": \"Peak GPU (driver) Used (MB)\",\n",
    "    \"patterns_found\": \"Patterns Found\",\n",
    "    \"theory_static_mb\": \"Theoretical Static Memory (MB)\",\n",
    "    \"theory_peak_mb\": \"Theoretical Peak Memory (MB)\",\n",
    "}\n",
    "\n",
    "def _plot_metric(df: pd.DataFrame, metric: str, out_dir: Path, dataset_name: str):\n",
    "    if metric not in df.columns:\n",
    "        print(f\"[plot] Skip missing metric: {metric}\")\n",
    "        return\n",
    "    # drop NaNs for this metric\n",
    "    dfm = df.dropna(subset=[metric])\n",
    "    if dfm.empty:\n",
    "        print(f\"[plot] No data for {metric}, skipping.\")\n",
    "        return\n",
    "    fig, ax = plt.subplots(figsize=(5.0, 3.0))\n",
    "    for algo, sub in dfm.groupby(\"algorithm\", sort=False):\n",
    "        sub = sub.sort_values(\"support_quant_int\")\n",
    "        ax.plot(sub[\"support_quant_int\"].values, sub[metric].values, marker=\"o\", label=algo)\n",
    "    ax.set_xlabel(\"Support Threshold (quantized int)\")\n",
    "    ax.set_ylabel(_LABELS.get(metric, metric))\n",
    "    ax.set_title(f\"{dataset_name} — {_LABELS.get(metric, metric)}\")\n",
    "    ax.grid(alpha=0.25, linestyle=\":\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    fig.tight_layout()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    pdf = out_dir / f\"{dataset_name}_{metric}.pdf\"\n",
    "    fig.savefig(pdf, format=\"pdf\"); plt.close(fig)\n",
    "    print(f\"[plot] wrote {pdf}\")\n",
    "\n",
    "def plot_all(metrics_df: pd.DataFrame, dataset_name: str, figs_dir: Path, metrics: Optional[List[str]]=None):\n",
    "    # Default now uses theoretical peak memory instead of driver memory\n",
    "    ms = metrics or [\"exec_time\", \"cpu_mem_mb\", \"theory_peak_mb\", \"patterns_found\"]\n",
    "    for m in ms: _plot_metric(metrics_df, m, figs_dir, dataset_name)\n",
    "    print(\"[plot] done.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Orchestrator (one-liner for your runs)\n",
    "# ----------------------------------------\n",
    "def run_pipeline(\n",
    "    dataset_url: str,\n",
    "    sf: int,\n",
    "    supports_quant_int: List[int],\n",
    "    *,\n",
    "    # cuFFI toggles\n",
    "    cuffi_allocator: str = \"rmm_managed\",\n",
    "    cuffi_gds: str = \"off\",      # 'off' => cuFile => GDS ON ; 'on' => POSIX => GDS OFF\n",
    "    cuffi_pinned: bool = False,\n",
    "    cuffi_prefetch: bool = True,\n",
    "    force: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Prep artifacts (URL + SF)\n",
    "    2) Run cuFFIMiner (GDS+UVM) AND naiveFFIMiner (no-GDS + device-only) in subprocesses\n",
    "    3) Parse logs -> CSV -> plots (uses *theoretical* peak memory)\n",
    "    \"\"\"\n",
    "    prep = prepare_dataset(dataset_url, sf)\n",
    "    dataset = prep[\"dataset_name\"]; quant_mult = prep[\"quant_mult\"]\n",
    "    ds_dir = RESULTS_DIR / dataset / f\"SF{sf}\"\n",
    "    logs_dir = ds_dir / \"logs\"; logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Run all supports\n",
    "    for sup in supports_quant_int:\n",
    "        cuffi_out = logs_dir / f\"cuffi_sup{sup}.out\"\n",
    "        naive_out = logs_dir / f\"naive_sup{sup}.out\"\n",
    "\n",
    "        if (not cuffi_out.exists()) or force:\n",
    "            run_cuffi_cli(\n",
    "                fixed_parquet=prep[\"fixed_parquet\"],\n",
    "                quant_mult=quant_mult,\n",
    "                sup_int=sup,\n",
    "                out_dir=ds_dir,\n",
    "                allocator=cuffi_allocator,\n",
    "                gds=cuffi_gds,\n",
    "                pinned=cuffi_pinned,\n",
    "                managed_prefetch=cuffi_prefetch,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"[skip] cuFFI sup={sup} (log exists, use force=True to re-run)\")\n",
    "\n",
    "        if (not naive_out.exists()) or force:\n",
    "            run_naive_cli(\n",
    "                floating_text_or_parquet=prep[\"floating_parquet\"],\n",
    "                quant_mult=quant_mult,\n",
    "                sup_int=sup,\n",
    "                out_dir=ds_dir,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"[skip] naive sup={sup} (log exists, use force=True to re-run)\")\n",
    "\n",
    "    # Collect -> CSV\n",
    "    df = collect_results(dataset, sf, quant_mult, supports_quant_int, ds_dir)\n",
    "    metrics_csv = ds_dir / f\"metrics_SF{sf}.csv\"\n",
    "    df.to_csv(metrics_csv, index=False)\n",
    "    print(f\"[metrics] saved {metrics_csv}\")\n",
    "\n",
    "    # Plot (theory peak memory by default)\n",
    "    plot_all(df, dataset, ds_dir / \"figures\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fb90bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail.csv\n",
      "[prep] Using existing: Fuzzy_retail_SF100_floating.csv\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.cuFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_fixed.parquet 25000 10 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_cuffi_rmm_managed_off_nopin_sup25000.txt --allocator rmm_managed --gds off --managed-prefetch\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup25000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup25000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.naiveFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_floating.parquet 2500 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_naive_sup25000.txt\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup25000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup25000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.cuFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_fixed.parquet 70000 10 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_cuffi_rmm_managed_off_nopin_sup70000.txt --allocator rmm_managed --gds off --managed-prefetch\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup70000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup70000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.naiveFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_floating.parquet 7000 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_naive_sup70000.txt\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup70000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup70000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.cuFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_fixed.parquet 100000 10 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_cuffi_rmm_managed_off_nopin_sup100000.txt --allocator rmm_managed --gds off --managed-prefetch\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup100000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup100000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.naiveFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_floating.parquet 10000 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_naive_sup100000.txt\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup100000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup100000.err\n",
      "[metrics] saved /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/metrics_SF100.csv\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_exec_time.pdf\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_cpu_mem_mb.pdf\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_theory_peak_mb.pdf\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_patterns_found.pdf\n",
      "[plot] done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sf</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_mb</th>\n",
       "      <th>pool_used_mb</th>\n",
       "      <th>pool_total_mb</th>\n",
       "      <th>rmm_peak_mb</th>\n",
       "      <th>patterns_found</th>\n",
       "      <th>theory_static_mb</th>\n",
       "      <th>theory_peak_mb</th>\n",
       "      <th>theory_peak_bytes</th>\n",
       "      <th>gpu_mem_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>25000</td>\n",
       "      <td>10</td>\n",
       "      <td>22.4061</td>\n",
       "      <td>931.05</td>\n",
       "      <td>14048.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10961.17</td>\n",
       "      <td>26746.0</td>\n",
       "      <td>7530.605</td>\n",
       "      <td>7874.331</td>\n",
       "      <td>8.256835e+09</td>\n",
       "      <td>1.473098e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>25000</td>\n",
       "      <td>10</td>\n",
       "      <td>39.3420</td>\n",
       "      <td>15618.12</td>\n",
       "      <td>40976.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6799.45</td>\n",
       "      <td>26746.0</td>\n",
       "      <td>6253.230</td>\n",
       "      <td>6596.956</td>\n",
       "      <td>6.917410e+09</td>\n",
       "      <td>4.296704e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>70000</td>\n",
       "      <td>10</td>\n",
       "      <td>6.5886</td>\n",
       "      <td>928.52</td>\n",
       "      <td>11766.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9036.76</td>\n",
       "      <td>6023.0</td>\n",
       "      <td>5699.432</td>\n",
       "      <td>5743.922</td>\n",
       "      <td>6.022939e+09</td>\n",
       "      <td>1.233813e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>70000</td>\n",
       "      <td>10</td>\n",
       "      <td>22.4037</td>\n",
       "      <td>15443.61</td>\n",
       "      <td>41000.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4762.63</td>\n",
       "      <td>6023.0</td>\n",
       "      <td>4691.932</td>\n",
       "      <td>4736.422</td>\n",
       "      <td>4.966498e+09</td>\n",
       "      <td>4.299220e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.8357</td>\n",
       "      <td>936.66</td>\n",
       "      <td>11046.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8317.50</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>5014.862</td>\n",
       "      <td>5033.807</td>\n",
       "      <td>5.278329e+09</td>\n",
       "      <td>1.158316e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>20.1205</td>\n",
       "      <td>14443.91</td>\n",
       "      <td>40980.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4161.71</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>4131.612</td>\n",
       "      <td>4150.557</td>\n",
       "      <td>4.352174e+09</td>\n",
       "      <td>4.297123e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset   sf      algorithm  support_quant_int  quant_mult  exec_time  \\\n",
       "0  Fuzzy_retail  100     cuFFIMiner              25000          10    22.4061   \n",
       "1  Fuzzy_retail  100  naiveFFIMiner              25000          10    39.3420   \n",
       "2  Fuzzy_retail  100     cuFFIMiner              70000          10     6.5886   \n",
       "3  Fuzzy_retail  100  naiveFFIMiner              70000          10    22.4037   \n",
       "4  Fuzzy_retail  100     cuFFIMiner             100000          10     4.8357   \n",
       "5  Fuzzy_retail  100  naiveFFIMiner             100000          10    20.1205   \n",
       "\n",
       "   cpu_mem_mb  gpu_mem_mb  pool_used_mb  pool_total_mb  rmm_peak_mb  \\\n",
       "0      931.05    14048.56           0.0            0.0     10961.17   \n",
       "1    15618.12    40976.56           0.0            0.0      6799.45   \n",
       "2      928.52    11766.56           0.0            0.0      9036.76   \n",
       "3    15443.61    41000.56           0.0            0.0      4762.63   \n",
       "4      936.66    11046.56           0.0            0.0      8317.50   \n",
       "5    14443.91    40980.56           0.0            0.0      4161.71   \n",
       "\n",
       "   patterns_found  theory_static_mb  theory_peak_mb  theory_peak_bytes  \\\n",
       "0         26746.0          7530.605        7874.331       8.256835e+09   \n",
       "1         26746.0          6253.230        6596.956       6.917410e+09   \n",
       "2          6023.0          5699.432        5743.922       6.022939e+09   \n",
       "3          6023.0          4691.932        4736.422       4.966498e+09   \n",
       "4          3530.0          5014.862        5033.807       5.278329e+09   \n",
       "5          3530.0          4131.612        4150.557       4.352174e+09   \n",
       "\n",
       "   gpu_mem_bytes  \n",
       "0   1.473098e+10  \n",
       "1   4.296704e+10  \n",
       "2   1.233813e+10  \n",
       "3   4.299220e+10  \n",
       "4   1.158316e+10  \n",
       "5   4.297123e+10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv\"\n",
    "# retail_sup = [25_000, 50_000, 60_000, 70_000, 80_000, 90_000, 100_000]\n",
    "retail_sup = [25_000, 70_000, 100_000]\n",
    "\n",
    "\n",
    "run_pipeline(retail, sf=100, supports_quant_int=retail_sup, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efdce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Using cached: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail.csv\n",
      "[prep] Using existing: Fuzzy_retail_SF100_floating.csv\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.cuFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_fixed.parquet 25000 10 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_cuffi_rmm_managed_off_nopin_sup25000.txt --allocator rmm_managed --gds off --managed-prefetch\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup25000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup25000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.naiveFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_floating.parquet 2500 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_naive_sup25000.txt\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup25000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup25000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.cuFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_fixed.parquet 70000 10 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_cuffi_rmm_managed_off_nopin_sup70000.txt --allocator rmm_managed --gds off --managed-prefetch\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup70000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup70000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.naiveFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_floating.parquet 7000 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_naive_sup70000.txt\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup70000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup70000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.cuFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_fixed.parquet 100000 10 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_cuffi_rmm_managed_off_nopin_sup100000.txt --allocator rmm_managed --gds off --managed-prefetch\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup100000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/cuffi_sup100000.err\n",
      "[run]  /export/home1/ltarun/miniforge3/envs/rapids-25.08/bin/python -m src.algorithms.fuzzy.naiveFFIMiner /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail_SF100_floating.parquet 10000 -o /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/patterns_naive_sup100000.txt\n",
      "[run] exit=0  log=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup100000.out  err=/export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/logs/naive_sup100000.err\n",
      "[metrics] saved /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/metrics_SF100.csv\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_exec_time.pdf\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_cpu_mem_mb.pdf\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_theory_peak_mb.pdf\n",
      "[plot] wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_retail/SF100/figures/Fuzzy_retail_patterns_found.pdf\n",
      "[plot] done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sf</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_mb</th>\n",
       "      <th>pool_used_mb</th>\n",
       "      <th>pool_total_mb</th>\n",
       "      <th>rmm_peak_mb</th>\n",
       "      <th>patterns_found</th>\n",
       "      <th>theory_static_mb</th>\n",
       "      <th>theory_peak_mb</th>\n",
       "      <th>theory_peak_bytes</th>\n",
       "      <th>gpu_mem_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>25000</td>\n",
       "      <td>10</td>\n",
       "      <td>10.1850</td>\n",
       "      <td>951.41</td>\n",
       "      <td>35170.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10961.17</td>\n",
       "      <td>26746.0</td>\n",
       "      <td>7530.605</td>\n",
       "      <td>7874.331</td>\n",
       "      <td>8.256835e+09</td>\n",
       "      <td>3.687901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>25000</td>\n",
       "      <td>10</td>\n",
       "      <td>38.9993</td>\n",
       "      <td>15619.10</td>\n",
       "      <td>40996.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6799.45</td>\n",
       "      <td>26746.0</td>\n",
       "      <td>6253.230</td>\n",
       "      <td>6596.956</td>\n",
       "      <td>6.917410e+09</td>\n",
       "      <td>4.298801e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>70000</td>\n",
       "      <td>10</td>\n",
       "      <td>5.8501</td>\n",
       "      <td>945.36</td>\n",
       "      <td>34590.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9036.76</td>\n",
       "      <td>6023.0</td>\n",
       "      <td>5699.432</td>\n",
       "      <td>5743.922</td>\n",
       "      <td>6.022939e+09</td>\n",
       "      <td>3.627083e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>70000</td>\n",
       "      <td>10</td>\n",
       "      <td>22.2785</td>\n",
       "      <td>15446.74</td>\n",
       "      <td>40984.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4762.63</td>\n",
       "      <td>6023.0</td>\n",
       "      <td>4691.932</td>\n",
       "      <td>4736.422</td>\n",
       "      <td>4.966498e+09</td>\n",
       "      <td>4.297543e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.7355</td>\n",
       "      <td>940.79</td>\n",
       "      <td>31878.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8317.50</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>5014.862</td>\n",
       "      <td>5033.807</td>\n",
       "      <td>5.278329e+09</td>\n",
       "      <td>3.342709e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuzzy_retail</td>\n",
       "      <td>100</td>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>19.7776</td>\n",
       "      <td>14452.34</td>\n",
       "      <td>40976.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4161.71</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>4131.612</td>\n",
       "      <td>4150.557</td>\n",
       "      <td>4.352174e+09</td>\n",
       "      <td>4.296704e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset   sf      algorithm  support_quant_int  quant_mult  exec_time  \\\n",
       "0  Fuzzy_retail  100     cuFFIMiner              25000          10    10.1850   \n",
       "1  Fuzzy_retail  100  naiveFFIMiner              25000          10    38.9993   \n",
       "2  Fuzzy_retail  100     cuFFIMiner              70000          10     5.8501   \n",
       "3  Fuzzy_retail  100  naiveFFIMiner              70000          10    22.2785   \n",
       "4  Fuzzy_retail  100     cuFFIMiner             100000          10     4.7355   \n",
       "5  Fuzzy_retail  100  naiveFFIMiner             100000          10    19.7776   \n",
       "\n",
       "   cpu_mem_mb  gpu_mem_mb  pool_used_mb  pool_total_mb  rmm_peak_mb  \\\n",
       "0      951.41    35170.56           0.0            0.0     10961.17   \n",
       "1    15619.10    40996.56           0.0            0.0      6799.45   \n",
       "2      945.36    34590.56           0.0            0.0      9036.76   \n",
       "3    15446.74    40984.56           0.0            0.0      4762.63   \n",
       "4      940.79    31878.56           0.0            0.0      8317.50   \n",
       "5    14452.34    40976.56           0.0            0.0      4161.71   \n",
       "\n",
       "   patterns_found  theory_static_mb  theory_peak_mb  theory_peak_bytes  \\\n",
       "0         26746.0          7530.605        7874.331       8.256835e+09   \n",
       "1         26746.0          6253.230        6596.956       6.917410e+09   \n",
       "2          6023.0          5699.432        5743.922       6.022939e+09   \n",
       "3          6023.0          4691.932        4736.422       4.966498e+09   \n",
       "4          3530.0          5014.862        5033.807       5.278329e+09   \n",
       "5          3530.0          4131.612        4150.557       4.352174e+09   \n",
       "\n",
       "   gpu_mem_bytes  \n",
       "0   3.687901e+10  \n",
       "1   4.298801e+10  \n",
       "2   3.627083e+10  \n",
       "3   4.297543e+10  \n",
       "4   3.342709e+10  \n",
       "5   4.296704e+10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv\"\n",
    "# retail_sup = [25_000, 50_000, 60_000, 70_000, 80_000, 90_000, 100_000]\n",
    "retail_sup = [25_000, 70_000, 100_000]\n",
    "\n",
    "\n",
    "run_pipeline(retail, sf=100, supports_quant_int=retail_sup, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kosarak = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv\"\n",
    "kosarak_sup = [250_000, 300_000, 350_000, 400_000, 450_000, 500_000, 550_000, 600_000, 650_000, 700_000]\n",
    "\n",
    "run_pipeline(kosarak, sf=100, supports_quant_int=kosarak_sup, force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pumsb = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv\"\n",
    "pumsb_sup = [20_000_000, 19_000_000, 18_000_000, 17_000_000,16_000_000]\n",
    "\n",
    "run_pipeline(pumsb, sf=100, supports_quant_int=pumsb_sup, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab04144",
   "metadata": {},
   "outputs": [],
   "source": [
    "pumsb = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_T10I4D100K.csv\"\n",
    "pumsb_sup = [550_000, 500_000, 450_000, 400_000, 350_000, 300_000, 200_000]\n",
    "\n",
    "run_pipeline(pumsb, sf=100, supports_quant_int=pumsb_sup, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577f75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
