{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111744c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported cuFFIMiner and naiveFFIMiner.\n",
      "Project Root: /export/home1/ltarun/cuda_pami\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# This code adds the project's root directory to the Python path.\n",
    "# This is necessary so that both the 'src' and 'scripts' directories can be found.\n",
    "project_root = Path(os.getcwd()).parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Now we can import the miners and script functions using their full paths from the root\n",
    "from src.algorithms.fuzzy.cuFFIMiner import cuFFIMiner\n",
    "from src.algorithms.fuzzy.naiveFFIMiner import naiveFFIMiner\n",
    "\n",
    "print(\"Successfully imported cuFFIMiner and naiveFFIMiner.\")\n",
    "print(f\"Project Root: {project_root}\")\n",
    "\n",
    "data_dir = project_root / 'data' / 'fuzzy'\n",
    "results_dir = project_root / 'results' / 'fuzzy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31a97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, time, requests\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import importlib\n",
    "from scripts import fixedpoint_normalize as _fpn_mod\n",
    "import matplotlib.pyplot as plt\n",
    "# ensure latest version of module (avoid stale cached copy)\n",
    "importlib.reload(_fpn_mod)\n",
    "from scripts.replicate_file import replicate_file\n",
    "from scripts.fixedpoint_normalize import normalize_file\n",
    "\n",
    "\n",
    "def _dataset_filename_from_url(url: str) -> str:\n",
    "    return Path(url.split(\"?\")[0]).name  # e.g. Fuzzy_retail.csv\n",
    "\n",
    "def _dataset_name_no_ext(filename: str) -> str:\n",
    "    return Path(filename).stem  # e.g. Fuzzy_retail\n",
    "\n",
    "# We will place each dataset inside its own subfolder under data_dir\n",
    "\n",
    "def download_dataset(url: str, base_data_dir: Path) -> Path:\n",
    "    filename = _dataset_filename_from_url(url)\n",
    "    name_root = _dataset_name_no_ext(filename)\n",
    "    dataset_dir = base_data_dir / name_root\n",
    "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "    local_path = dataset_dir / filename\n",
    "    if local_path.exists():\n",
    "        print(f\"[download] Existing: {local_path}\")\n",
    "        return local_path\n",
    "    # Fallback: if legacy path (without subfolder) exists, move it\n",
    "    legacy_path = base_data_dir / filename\n",
    "    if legacy_path.exists():\n",
    "        print(f\"[download] Moving legacy file into subfolder: {legacy_path} -> {local_path}\")\n",
    "        local_path.write_bytes(legacy_path.read_bytes())\n",
    "        return local_path\n",
    "    print(f\"[download] Fetch {url}\")\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    local_path.write_bytes(r.content)\n",
    "    print(f\"[download] Saved {local_path}\")\n",
    "    return local_path\n",
    "\n",
    "\n",
    "def ensure_floating_sf(original: Path, sf: int) -> Path:\n",
    "    if sf < 1: sf = 1\n",
    "    float_path = original.with_name(f\"{original.stem}_SF{sf}_floating{original.suffix}\")\n",
    "    if float_path.exists():\n",
    "        print(f\"[SF] Using existing floating SF file: {float_path.name}\")\n",
    "        return float_path\n",
    "    replicate_file(str(original), sf, str(float_path))\n",
    "    return float_path\n",
    "\n",
    "def ensure_fixed_variant(floating_path: Path) -> Tuple[Path, int]:\n",
    "    stem = floating_path.stem.replace('_floating','')  # e.g. base_SF10\n",
    "    fixed_path = floating_path.with_name(f\"{stem}_fixed.parquet\")\n",
    "    quant_file = floating_path.with_name(f\"{stem}_quant_mult.txt\")\n",
    "    # Backward compatibility: if only old scale file exists, read it and rename\n",
    "    legacy_scale = floating_path.with_name(f\"{stem}_scale.txt\")\n",
    "    if fixed_path.exists() and quant_file.exists():\n",
    "        quant_val = int(quant_file.read_text().strip())\n",
    "        print(f\"[fixed] Reusing existing fixed file: {fixed_path.name} quant_mult={quant_val}\")\n",
    "        return fixed_path, quant_val\n",
    "    if fixed_path.exists() and legacy_scale.exists():\n",
    "        quant_val = int(legacy_scale.read_text().strip())\n",
    "        quant_file.write_text(str(quant_val)+'\\n')\n",
    "        print(f\"[fixed] Upgraded legacy scale -> quant_mult: {legacy_scale.name} -> {quant_file.name}\")\n",
    "        return fixed_path, quant_val\n",
    "    fixed_generated, quant_val = normalize_file(str(floating_path), write_fixed_text=False)\n",
    "    return Path(fixed_generated), quant_val\n",
    "\n",
    "def ensure_fixed_parquet(fixed_text: Path) -> Path:\n",
    "    # GPU pipeline already produced parquet alongside fixed text; just return if exists\n",
    "    parquet_path = fixed_text.with_suffix('.parquet')\n",
    "    if parquet_path.exists():\n",
    "        print(f\"[parquet-fixed] Existing: {parquet_path.name}\")\n",
    "        return parquet_path\n",
    "    raise FileNotFoundError(f\"Expected parquet produced by pipeline missing: {parquet_path}\")\n",
    "\n",
    "def ensure_floating_parquet(floating_text: Path) -> Path:\n",
    "    \"\"\"Return floating parquet (produced by pipeline).\"\"\"\n",
    "    parquet_path = floating_text.with_suffix('.parquet')\n",
    "    if parquet_path.exists():\n",
    "        return parquet_path\n",
    "    # If not present user likely hasn't run normalization yet; trigger pipeline via normalize_file\n",
    "    normalize_file(str(floating_text), write_fixed_text=False)\n",
    "    if parquet_path.exists():\n",
    "        return parquet_path\n",
    "    raise FileNotFoundError(f\"Floating parquet not found: {parquet_path}\")\n",
    "\n",
    "# Mapping supports\n",
    "\n",
    "def support_to_float(support_int: int, quant_mult: int) -> float:\n",
    "    if quant_mult > 0:\n",
    "        return support_int / quant_mult\n",
    "    return float(support_int)\n",
    "\n",
    "# Mining both miners with unified quant_mult\n",
    "\n",
    "def run_both_miners(fixed_parquet: Path, floating_parquet: Path, quant_mult: int, supports_scaled: List[int], results_subdir: Path, memory_type: str = \"global\", debug: bool = False) -> pd.DataFrame:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    results_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for sup_int in supports_scaled:\n",
    "        cuffi_patterns_path = results_subdir / f\"patterns_cuffi_sup{sup_int}.txt\"\n",
    "        if cuffi_patterns_path.exists():\n",
    "            print(f\"[cuFFIMiner] Skip sup={sup_int} (exists)\")\n",
    "        else:\n",
    "            try:\n",
    "                algo_c = cuFFIMiner(str(fixed_parquet), min_support=sup_int, scaling_factor=quant_mult, memory_type=memory_type, debug=debug)\n",
    "                algo_c.mine(); algo_c.save(cuffi_patterns_path); algo_c.print_results()\n",
    "                rows.append({\"algorithm\":\"cuFFIMiner\",\"support_quant_int\":sup_int,\"quant_mult\":quant_mult,\"exec_time\":algo_c.get_execution_time(),\"cpu_mem_mb\":algo_c.get_memory_usage(),\"gpu_mem_bytes\":getattr(algo_c,'_gpu_memory_usage',None),\"patterns_found\":algo_c.get_pattern_count()})\n",
    "            except Exception as e:\n",
    "                print(f\"[cuFFIMiner][ERROR] sup={sup_int}: {e}\")\n",
    "                rows.append({\"algorithm\":\"cuFFIMiner\",\"support_quant_int\":sup_int,\"quant_mult\":quant_mult,\"error\":str(e)})\n",
    "\n",
    "        sup_float = support_to_float(sup_int, quant_mult)\n",
    "        print('sup_float:', sup_float)\n",
    "        print(f\"[naiveFFIMiner] quant_int={sup_int} -> float={sup_float} (forced quant_mult={quant_mult})\")\n",
    "        naive_patterns_path = results_subdir / f\"patterns_naive_sup{sup_int}.txt\"\n",
    "        if naive_patterns_path.exists():\n",
    "            print(f\"[naiveFFIMiner] Skip sup={sup_int} (exists)\")\n",
    "        else:\n",
    "            try:\n",
    "                algo_n = naiveFFIMiner(str(floating_parquet), min_support=sup_float, quant_mult=quant_mult, debug=debug)\n",
    "                algo_n.mine(); algo_n.save(naive_patterns_path); algo_n.print_results()\n",
    "                rows.append({\"algorithm\":\"naiveFFIMiner\",\"support_quant_int\":sup_int,\"support_float\":sup_float,\"quant_mult\":quant_mult,\"exec_time\":algo_n.get_execution_time(),\"cpu_mem_mb\":algo_n.get_memory_usage(),\"gpu_mem_bytes\":getattr(algo_n,'_gpu_memory_usage',None),\"patterns_found\":algo_n.get_pattern_count()})\n",
    "            except Exception as e:\n",
    "                print(f\"[naiveFFIMiner][ERROR] sup={sup_int}: {e}\")\n",
    "                rows.append({\"algorithm\":\"naiveFFIMiner\",\"support_quant_int\":sup_int,\"support_float\":sup_float,\"quant_mult\":quant_mult,\"error\":str(e)})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd475f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "    'figure.dpi': 150,\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'axes.labelsize': 11,\n",
    "    'legend.fontsize': 9,\n",
    "})\n",
    "\n",
    "_METRIC_LABELS = {\n",
    "    'exec_time': 'Execution Time (s)',\n",
    "    'cpu_mem_mb': 'Peak CPU Memory (MB)',\n",
    "    'gpu_mem_bytes': 'GPU Memory (MB)',\n",
    "    'patterns_found': 'Patterns Found',\n",
    "}\n",
    "\n",
    "DEFAULT_FIG_CFG = {\n",
    "    'width': 5.0,\n",
    "    'height': 3.0,\n",
    "    'legend_loc': 'best',\n",
    "    'tight_layout': True,\n",
    "}\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _prep_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    if 'gpu_mem_bytes' in d.columns:\n",
    "        d['gpu_mem_mb'] = d['gpu_mem_bytes'] / (1024**2)\n",
    "    return d\n",
    "\n",
    "def plot_metric(df: pd.DataFrame, metric: str, dataset_name: str, output_dir: Path,\n",
    "                fig_cfg: dict | None = None, scale_x: bool = False):\n",
    "    cfg = {**DEFAULT_FIG_CFG, **(fig_cfg or {})}\n",
    "    d = _prep_df(df)\n",
    "    if metric == 'gpu_mem_mb' and 'gpu_mem_mb' not in d.columns:\n",
    "        print('Skipping gpu_mem_mb (not present)')\n",
    "        return\n",
    "    xcol = 'support_quant_int'\n",
    "    if scale_x and 'quant_mult' in d.columns:\n",
    "        x = d[xcol] * d['quant_mult']\n",
    "        xlabel = 'Support Threshold (raw * quant_mult)'\n",
    "    else:\n",
    "        x = d[xcol]\n",
    "        xlabel = 'Support Threshold (quantized int)'\n",
    "    fig, ax = plt.subplots(figsize=(cfg['width'], cfg['height']))\n",
    "    for algo, sub in d.groupby('algorithm'):\n",
    "        ycol = metric if metric != 'gpu_mem_mb' else 'gpu_mem_mb'\n",
    "        ax.plot(x.loc[sub.index], sub[ycol], marker='o', label=algo)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(_METRIC_LABELS.get(metric, metric))\n",
    "    ax.set_title(f\"{dataset_name} â€“ {_METRIC_LABELS.get(metric, metric)}\")\n",
    "    ax.grid(alpha=0.25, linestyle=':')\n",
    "    ax.legend(loc=cfg['legend_loc'])\n",
    "    if cfg.get('tight_layout', True):\n",
    "        fig.tight_layout()\n",
    "    _ensure_dir(output_dir)\n",
    "    out_file = output_dir / f\"{dataset_name}_{metric}.pdf\"\n",
    "    fig.savefig(out_file, format='pdf')\n",
    "    plt.close(fig)\n",
    "    print(f\"[figure] Wrote {out_file}\")\n",
    "\n",
    "def generate_all_figures(dataset_name: str, metrics_df: pd.DataFrame | None = None,\n",
    "                          metrics_path: Path | None = None, output_subdir: str = 'figures',\n",
    "                          metrics: list[str] | None = None, fig_cfg: dict | None = None,\n",
    "                          scale_x: bool = False):\n",
    "    if metrics_df is None:\n",
    "        if metrics_path:\n",
    "            metrics_df = pd.read_csv(metrics_path)\n",
    "        else:\n",
    "            ds_dir = results_dir / dataset_name\n",
    "            files = sorted(ds_dir.glob('metrics_SF*.csv'))\n",
    "            if not files:\n",
    "                raise FileNotFoundError(f\"No metrics file found in {ds_dir}\")\n",
    "            dfs = [pd.read_csv(f) for f in files]\n",
    "            metrics_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "    if metrics is None:\n",
    "        metrics = ['exec_time','cpu_mem_mb','gpu_mem_mb','patterns_found']\n",
    "    out_dir = results_dir / dataset_name / output_subdir\n",
    "    for m in metrics:\n",
    "        if m not in metrics_df.columns and not (m == 'gpu_mem_mb' and 'gpu_mem_bytes' in metrics_df.columns):\n",
    "            print(f\"[figure] Skip missing metric: {m}\")\n",
    "            continue\n",
    "        plot_metric(metrics_df, m, dataset_name, out_dir, fig_cfg=fig_cfg, scale_x=scale_x)\n",
    "    print(\"[figure] All requested figures generated.\")\n",
    "\n",
    "def run_experiment(dataset_url: str, sf: int, supports_quant_int: List[int], memory_type: str = 'global', debug: bool = False,\n",
    "                   generate_figures: bool = True, fig_metrics: List[str] | None = None, fig_cfg: Dict[str, Any] | None = None,\n",
    "                   scale_x: bool = False, fig_subdir: str = 'figures') -> pd.DataFrame:\n",
    "    print(\"========== RUN EXPERIMENT (SF + quant_mult unified) ==========\")\n",
    "    print(f\"Dataset URL : {dataset_url}\")\n",
    "    print(f\"SF (concat) : {sf}\")\n",
    "    print(f\"Quantized integer supports: {supports_quant_int}\")\n",
    "\n",
    "    original = download_dataset(dataset_url, data_dir)\n",
    "    dataset_name = original.parent.name\n",
    "    floating_sf_text = ensure_floating_sf(original, sf)\n",
    "    fixed_parquet, quant_mult = ensure_fixed_variant(floating_sf_text)\n",
    "\n",
    "    floating_parquet = ensure_floating_parquet(floating_sf_text)\n",
    "\n",
    "    result_dir = results_dir / dataset_name\n",
    "    metrics_df = run_both_miners(fixed_parquet, floating_parquet, quant_mult, supports_quant_int, result_dir, memory_type=memory_type, debug=debug)\n",
    "\n",
    "    metrics_file = result_dir / f\"metrics_SF{sf}.csv\"\n",
    "    if not metrics_file.exists() or len(metrics_df) > 0:\n",
    "        metrics_df.to_csv(metrics_file, index=False)\n",
    "        print(f\"[metrics] Saved {metrics_file}\")\n",
    "\n",
    "    if generate_figures:\n",
    "        try:\n",
    "            generate_all_figures(dataset_name, metrics_df=metrics_df, metrics=fig_metrics, fig_cfg=fig_cfg, scale_x=scale_x, output_subdir=fig_subdir)\n",
    "        except Exception as e:\n",
    "            print(f\"[figure][ERROR] {e}\")\n",
    "\n",
    "    print(\"============ DONE ============\")\n",
    "    return metrics_df\n",
    "\n",
    "run_complete_experiment = run_experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fb90bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RUN EXPERIMENT (SF + quant_mult unified) ==========\n",
      "Dataset URL : https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv\n",
      "SF (concat) : 100\n",
      "Quantized integer supports: [40000, 45000, 50000, 55000, 60000]\n",
      "[download] Existing: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_retail/Fuzzy_retail.csv\n",
      "[SF] Using existing floating SF file: Fuzzy_retail_SF100_floating.csv\n",
      "[fixed] Reusing existing fixed file: Fuzzy_retail_SF100_fixed.parquet quant_mult=10\n",
      "[cuFFIMiner] Skip sup=40000 (exists)\n",
      "sup_float: 4000.0\n",
      "[naiveFFIMiner] quant_int=40000 -> float=4000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=40000 (exists)\n",
      "[cuFFIMiner] Skip sup=45000 (exists)\n",
      "sup_float: 4500.0\n",
      "[naiveFFIMiner] quant_int=45000 -> float=4500.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=45000 (exists)\n",
      "[cuFFIMiner] Skip sup=50000 (exists)\n",
      "sup_float: 5000.0\n",
      "[naiveFFIMiner] quant_int=50000 -> float=5000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=50000 (exists)\n",
      "[cuFFIMiner] Skip sup=55000 (exists)\n",
      "sup_float: 5500.0\n",
      "[naiveFFIMiner] quant_int=55000 -> float=5500.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=55000 (exists)\n",
      "[cuFFIMiner] Skip sup=60000 (exists)\n",
      "sup_float: 6000.0\n",
      "[naiveFFIMiner] quant_int=60000 -> float=6000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=60000 (exists)\n",
      "[figure] Skip missing metric: exec_time\n",
      "[figure] Skip missing metric: cpu_mem_mb\n",
      "[figure] Skip missing metric: gpu_mem_mb\n",
      "[figure] Skip missing metric: patterns_found\n",
      "[figure] All requested figures generated.\n",
      "============ DONE ============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_retail.csv\"\n",
    "retail_sup = [40000, 45000, 50000, 55000, 60000]\n",
    "\n",
    "metrics_retail = run_experiment(retail, 100, retail_sup)\n",
    "metrics_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bfb2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RUN EXPERIMENT (SF + quant_mult unified) ==========\n",
      "Dataset URL : https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_connect.csv\n",
      "SF (concat) : 100\n",
      "Quantized integer supports: [25000000, 24500000, 24000000, 23500000, 23000000]\n",
      "[download] Existing: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_connect/Fuzzy_connect.csv\n",
      "[SF] Using existing floating SF file: Fuzzy_connect_SF100_floating.csv\n",
      "[fixed] Reusing existing fixed file: Fuzzy_connect_SF100_fixed.parquet quant_mult=10\n",
      "[cuFFIMiner] Skip sup=25000000 (exists)\n",
      "sup_float: 2500000.0\n",
      "[naiveFFIMiner] quant_int=25000000 -> float=2500000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=25000000 (exists)\n",
      "[cuFFIMiner] Skip sup=24500000 (exists)\n",
      "sup_float: 2450000.0\n",
      "[naiveFFIMiner] quant_int=24500000 -> float=2450000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=24500000 (exists)\n",
      "[cuFFIMiner] Skip sup=24000000 (exists)\n",
      "sup_float: 2400000.0\n",
      "[naiveFFIMiner] quant_int=24000000 -> float=2400000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=24000000 (exists)\n",
      "[cuFFIMiner] Skip sup=23500000 (exists)\n",
      "sup_float: 2350000.0\n",
      "[naiveFFIMiner] quant_int=23500000 -> float=2350000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=23500000 (exists)\n",
      "[cuFFIMiner] Skip sup=23000000 (exists)\n",
      "sup_float: 2300000.0\n",
      "[naiveFFIMiner] quant_int=23000000 -> float=2300000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=23000000 (exists)\n",
      "[figure] Skip missing metric: exec_time\n",
      "[figure] Skip missing metric: cpu_mem_mb\n",
      "[figure] Skip missing metric: gpu_mem_mb\n",
      "[figure] Skip missing metric: patterns_found\n",
      "[figure] All requested figures generated.\n",
      "============ DONE ============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_connect.csv\"\n",
    "connect_sup = [25000000, 24500000, 24000000, 23500000, 23000000]\n",
    "\n",
    "metrics_connect = run_experiment(connect, 100, connect_sup)\n",
    "metrics_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737eea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RUN EXPERIMENT (SF + quant_mult unified) ==========\n",
      "Dataset URL : https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv\n",
      "SF (concat) : 50\n",
      "Quantized integer supports: [600000, 700000, 800000, 900000, 1000000]\n",
      "[download] Existing: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_kosarak/Fuzzy_kosarak.csv\n",
      "[SF] Using existing floating SF file: Fuzzy_kosarak_SF50_floating.csv\n",
      "[fixed] Reusing existing fixed file: Fuzzy_kosarak_SF50_fixed.parquet quant_mult=10\n",
      "[cuFFIMiner] Skip sup=600000 (exists)\n",
      "sup_float: 60000.0\n",
      "[naiveFFIMiner] quant_int=600000 -> float=60000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=600000 (exists)\n",
      "[cuFFIMiner] Skip sup=700000 (exists)\n",
      "sup_float: 70000.0\n",
      "[naiveFFIMiner] quant_int=700000 -> float=70000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=700000 (exists)\n",
      "[cuFFIMiner] Skip sup=800000 (exists)\n",
      "sup_float: 80000.0\n",
      "[naiveFFIMiner] quant_int=800000 -> float=80000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=800000 (exists)\n",
      "[cuFFIMiner] Skip sup=900000 (exists)\n",
      "sup_float: 90000.0\n",
      "[naiveFFIMiner] quant_int=900000 -> float=90000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=900000 (exists)\n",
      "[cuFFIMiner] Skip sup=1000000 (exists)\n",
      "sup_float: 100000.0\n",
      "[naiveFFIMiner] quant_int=1000000 -> float=100000.0 (forced quant_mult=10)\n",
      "[naiveFFIMiner] Skip sup=1000000 (exists)\n",
      "[figure] Skip missing metric: exec_time\n",
      "[figure] Skip missing metric: cpu_mem_mb\n",
      "[figure] Skip missing metric: gpu_mem_mb\n",
      "[figure] Skip missing metric: patterns_found\n",
      "[figure] All requested figures generated.\n",
      "============ DONE ============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosarak = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_kosarak.csv\"\n",
    "kosarak_sup = [600000, 700000, 800000, 900000, 1000000]\n",
    "\n",
    "metrics_kosarak = run_experiment(kosarak, 50, kosarak_sup)\n",
    "metrics_kosarak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3f1e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RUN EXPERIMENT (SF + quant_mult unified) ==========\n",
      "Dataset URL : https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv\n",
      "SF (concat) : 100\n",
      "Quantized integer supports: [20000000, 19000000, 18000000, 17000000, 16000000]\n",
      "[download] Existing: /export/home1/ltarun/cuda_pami/data/fuzzy/Fuzzy_pumsb/Fuzzy_pumsb.csv\n",
      "[SF] Using existing floating SF file: Fuzzy_pumsb_SF100_floating.csv\n",
      "[fixed] Reusing existing fixed file: Fuzzy_pumsb_SF100_fixed.parquet quant_mult=10\n",
      "\n",
      "--- cuFFIMiner Results ---\n",
      "Execution Time: 22.3111 seconds\n",
      "Peak CPU Memory Usage: 984.95 MB\n",
      "Peak GPU Memory Usage: 22719.06 MB\n",
      "Patterns Found: 3384\n",
      "------------------------------\n",
      "sup_float: 2000000.0\n",
      "[naiveFFIMiner] quant_int=20000000 -> float=2000000.0 (forced quant_mult=10)\n",
      "\n",
      "--- naiveFFIMiner Results ---\n",
      "Execution Time: 29.4312 seconds\n",
      "Peak CPU Memory Usage: 21217.97 MB\n",
      "Peak GPU Memory Usage: 22719.06 MB\n",
      "Patterns Found: 3384\n",
      "---------------------------------\n",
      "\n",
      "--- cuFFIMiner Results ---\n",
      "Execution Time: 30.8682 seconds\n",
      "Peak CPU Memory Usage: 21282.16 MB\n",
      "Peak GPU Memory Usage: 23021.06 MB\n",
      "Patterns Found: 4840\n",
      "------------------------------\n",
      "sup_float: 1900000.0\n",
      "[naiveFFIMiner] quant_int=19000000 -> float=1900000.0 (forced quant_mult=10)\n",
      "\n",
      "--- naiveFFIMiner Results ---\n",
      "Execution Time: 38.2185 seconds\n",
      "Peak CPU Memory Usage: 22294.62 MB\n",
      "Peak GPU Memory Usage: 23021.06 MB\n",
      "Patterns Found: 4840\n",
      "---------------------------------\n",
      "\n",
      "--- cuFFIMiner Results ---\n",
      "Execution Time: 46.2702 seconds\n",
      "Peak CPU Memory Usage: 22294.62 MB\n",
      "Peak GPU Memory Usage: 23617.06 MB\n",
      "Patterns Found: 6983\n",
      "------------------------------\n",
      "sup_float: 1800000.0\n",
      "[naiveFFIMiner] quant_int=18000000 -> float=1800000.0 (forced quant_mult=10)\n",
      "\n",
      "--- naiveFFIMiner Results ---\n",
      "Execution Time: 53.0683 seconds\n",
      "Peak CPU Memory Usage: 22838.86 MB\n",
      "Peak GPU Memory Usage: 23617.06 MB\n",
      "Patterns Found: 6983\n",
      "---------------------------------\n",
      "\n",
      "--- cuFFIMiner Results ---\n",
      "Execution Time: 70.2470 seconds\n",
      "Peak CPU Memory Usage: 22838.86 MB\n",
      "Peak GPU Memory Usage: 23719.06 MB\n",
      "Patterns Found: 10196\n",
      "------------------------------\n",
      "sup_float: 1700000.0\n",
      "[naiveFFIMiner] quant_int=17000000 -> float=1700000.0 (forced quant_mult=10)\n",
      "\n",
      "--- naiveFFIMiner Results ---\n",
      "Execution Time: 75.2699 seconds\n",
      "Peak CPU Memory Usage: 23077.74 MB\n",
      "Peak GPU Memory Usage: 23719.06 MB\n",
      "Patterns Found: 10196\n",
      "---------------------------------\n",
      "\n",
      "--- cuFFIMiner Results ---\n",
      "Execution Time: 105.9887 seconds\n",
      "Peak CPU Memory Usage: 23077.74 MB\n",
      "Peak GPU Memory Usage: 24399.06 MB\n",
      "Patterns Found: 15240\n",
      "------------------------------\n",
      "sup_float: 1600000.0\n",
      "[naiveFFIMiner] quant_int=16000000 -> float=1600000.0 (forced quant_mult=10)\n",
      "\n",
      "--- naiveFFIMiner Results ---\n",
      "Execution Time: 113.8371 seconds\n",
      "Peak CPU Memory Usage: 23460.84 MB\n",
      "Peak GPU Memory Usage: 24397.06 MB\n",
      "Patterns Found: 15240\n",
      "---------------------------------\n",
      "[metrics] Saved /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/metrics_SF100.csv\n",
      "[figure] Wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/figures/Fuzzy_pumsb_exec_time.pdf\n",
      "[figure] Wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/figures/Fuzzy_pumsb_cpu_mem_mb.pdf\n",
      "[figure] Wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/figures/Fuzzy_pumsb_gpu_mem_mb.pdf\n",
      "[figure] Wrote /export/home1/ltarun/cuda_pami/results/fuzzy/Fuzzy_pumsb/figures/Fuzzy_pumsb_patterns_found.pdf\n",
      "[figure] All requested figures generated.\n",
      "============ DONE ============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>support_quant_int</th>\n",
       "      <th>quant_mult</th>\n",
       "      <th>exec_time</th>\n",
       "      <th>cpu_mem_mb</th>\n",
       "      <th>gpu_mem_bytes</th>\n",
       "      <th>patterns_found</th>\n",
       "      <th>support_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>20000000</td>\n",
       "      <td>10</td>\n",
       "      <td>22.311069</td>\n",
       "      <td>984.945312</td>\n",
       "      <td>23822663680</td>\n",
       "      <td>3384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>20000000</td>\n",
       "      <td>10</td>\n",
       "      <td>29.431204</td>\n",
       "      <td>21217.968750</td>\n",
       "      <td>23822663680</td>\n",
       "      <td>3384</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>19000000</td>\n",
       "      <td>10</td>\n",
       "      <td>30.868198</td>\n",
       "      <td>21282.160156</td>\n",
       "      <td>24139333632</td>\n",
       "      <td>4840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>19000000</td>\n",
       "      <td>10</td>\n",
       "      <td>38.218514</td>\n",
       "      <td>22294.625000</td>\n",
       "      <td>24139333632</td>\n",
       "      <td>4840</td>\n",
       "      <td>1900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>18000000</td>\n",
       "      <td>10</td>\n",
       "      <td>46.270154</td>\n",
       "      <td>22294.625000</td>\n",
       "      <td>24764284928</td>\n",
       "      <td>6983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>18000000</td>\n",
       "      <td>10</td>\n",
       "      <td>53.068277</td>\n",
       "      <td>22838.863281</td>\n",
       "      <td>24764284928</td>\n",
       "      <td>6983</td>\n",
       "      <td>1800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>17000000</td>\n",
       "      <td>10</td>\n",
       "      <td>70.247030</td>\n",
       "      <td>22838.863281</td>\n",
       "      <td>24871239680</td>\n",
       "      <td>10196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>17000000</td>\n",
       "      <td>10</td>\n",
       "      <td>75.269862</td>\n",
       "      <td>23077.738281</td>\n",
       "      <td>24871239680</td>\n",
       "      <td>10196</td>\n",
       "      <td>1700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cuFFIMiner</td>\n",
       "      <td>16000000</td>\n",
       "      <td>10</td>\n",
       "      <td>105.988672</td>\n",
       "      <td>23077.738281</td>\n",
       "      <td>25584271360</td>\n",
       "      <td>15240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>naiveFFIMiner</td>\n",
       "      <td>16000000</td>\n",
       "      <td>10</td>\n",
       "      <td>113.837074</td>\n",
       "      <td>23460.843750</td>\n",
       "      <td>25582174208</td>\n",
       "      <td>15240</td>\n",
       "      <td>1600000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       algorithm  support_quant_int  quant_mult   exec_time    cpu_mem_mb  \\\n",
       "0     cuFFIMiner           20000000          10   22.311069    984.945312   \n",
       "1  naiveFFIMiner           20000000          10   29.431204  21217.968750   \n",
       "2     cuFFIMiner           19000000          10   30.868198  21282.160156   \n",
       "3  naiveFFIMiner           19000000          10   38.218514  22294.625000   \n",
       "4     cuFFIMiner           18000000          10   46.270154  22294.625000   \n",
       "5  naiveFFIMiner           18000000          10   53.068277  22838.863281   \n",
       "6     cuFFIMiner           17000000          10   70.247030  22838.863281   \n",
       "7  naiveFFIMiner           17000000          10   75.269862  23077.738281   \n",
       "8     cuFFIMiner           16000000          10  105.988672  23077.738281   \n",
       "9  naiveFFIMiner           16000000          10  113.837074  23460.843750   \n",
       "\n",
       "   gpu_mem_bytes  patterns_found  support_float  \n",
       "0    23822663680            3384            NaN  \n",
       "1    23822663680            3384      2000000.0  \n",
       "2    24139333632            4840            NaN  \n",
       "3    24139333632            4840      1900000.0  \n",
       "4    24764284928            6983            NaN  \n",
       "5    24764284928            6983      1800000.0  \n",
       "6    24871239680           10196            NaN  \n",
       "7    24871239680           10196      1700000.0  \n",
       "8    25584271360           15240            NaN  \n",
       "9    25582174208           15240      1600000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pumsb = \"https://u-aizu.ac.jp/~udayrage/datasets/fuzzyDatabases/Fuzzy_pumsb.csv\"\n",
    "pumsb_sup = [20000000, 19000000, 18000000, 17000000, 16000000]\n",
    "\n",
    "metrics_pumsb = run_experiment(pumsb, 100, pumsb_sup)\n",
    "metrics_pumsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab04144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
